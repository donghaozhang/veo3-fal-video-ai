# AI Content Generation Project Overview

This project provides Python utilities for generating videos, images, and avatars using multiple AI platforms:

## Video Generation
1. **Google Veo API** on Vertex AI (higher resolution, automated setup with permission fixes)
2. **FAL AI Dual Models** (simpler setup, production ready)
   - **MiniMax Hailuo-02** (768p, prompt optimizer)
   - **Kling Video 2.1** (high-quality, CFG scale, negative prompts)
3. **NEW: FAL AI Text-to-Video** (direct text-to-video generation)
   - **MiniMax Hailuo-02 Pro** (1080p, $0.08/video, 6s duration)
   - **Google Veo 3** ($2.50-$6.00/video, 720p, 5-8s, audio support)

## Video Enhancement
4. **NEW: FAL AI Video-to-Video** (AI audio enhancement)
   - **ThinkSound API** (~$0.001/second, realistic audio generation)
   - **Text Prompts** (guide audio generation with natural language)
   - **Multiple Formats** (MP4, MOV, AVI, WebM support)

## Avatar Generation
5. **FAL AI Triple-Mode System** (talking avatars with lip-sync)
   - **Text-to-Speech**: 20 voice options with natural speech conversion
   - **Audio-to-Avatar**: Custom audio files for lip-sync animation
   - **Multi-Audio Conversation**: Two-person conversations with sequential speaking

## Text-to-Image Generation
6. **FAL AI Quad Models** (consolidated test structure, direct Python API)
   - **Imagen4** (Google's high-quality model)
   - **Seedream** (Artistic and creative generation)
   - **FLUX Schnell** (Ultra-fast generation)
   - **FLUX Dev** (Balanced speed and quality)

## Image-to-Image Generation
7. **FAL AI Image Enhancement** (comprehensive image transformation pipeline)
   - **FLUX Image Enhancement**: High-quality image refinement and style transfer
   - **Batch Processing**: Multiple image transformations with cost-conscious design
   - **Professional Package**: Modular architecture with setup.py and proper testing

## Text-to-Speech Generation
8. **ElevenLabs TTS Package** (modular architecture, comprehensive features)
   - **3000+ Voice Library**: Popular presets and custom voice cloning
   - **AI Content Pipeline**: OpenRouter AI integration with top 10 models
   - **Advanced Features**: Timing control, multi-speaker dialogue, emotional tags
   - **Professional Package**: Modular design with setup.py and proper imports

## Unified Content Pipeline
9. **NEW: AI Content Pipeline** (chain multiple AI operations)
   - **Text → Image → Video → Audio Enhancement → Video Upscaling**
   - **YAML/JSON Configuration**: Define complex workflows
   - **Automatic Model Selection**: Based on criteria and budget
   - **Cost Optimization**: Transparent pricing and estimation

## Main Components

### Google Veo Implementation
Located in [packages/providers/google/veo/](mdc:packages/providers/google/veo) directory with automated setup and permission fixes.

**Key Components:**
- [veo_video_generation.py](mdc:packages/providers/google/veo/veo_video_generation.py) - Main Google Veo video generation functions
- [fix_permissions.py](mdc:packages/providers/google/veo/fix_permissions.py) - **Automated permission fix tool** (fixes 90% of setup issues)
- [demo.py](mdc:packages/providers/google/veo/demo.py) - Interactive demonstration with Veo 2.0/3.0 selection
- [test_veo.py](mdc:packages/providers/google/veo/test_veo.py) - Comprehensive test suite with command-line options

**Key Functions:**
- `generate_video_from_text()` - Creates videos from text prompts
- `generate_video_from_image()` - Creates videos from images with optional text guidance
- `generate_video_from_local_image()` - Handles local image uploads to GCS
- `generate_video_with_veo3_preview()` - Uses the newer Veo 3.0 model
- `download_gcs_file()` - Downloads generated videos from Google Cloud Storage

**Quick Setup**: Run `python fix_permissions.py` to automatically configure Google Cloud permissions

### FAL AI Video Generation (Dual-Model)
Located in [packages/providers/fal/video/](mdc:packages/providers/fal/video) directory with simplified API-based approach supporting two models and cost-conscious testing.

**Key Components:**
- [fal_video_generator.py](mdc:packages/providers/fal/video/fal_video_generator.py) - Main FALVideoGenerator class with full endpoint names
- [demo.py](mdc:packages/providers/fal/video/demo.py) - Cost-conscious interactive demo with confirmation prompts
- [test_fal_ai.py](mdc:packages/providers/fal/video/test_fal_ai.py) - Cost-conscious test suite with model-specific flags
- [test_api_only.py](mdc:packages/providers/fal/video/test_api_only.py) - **FREE API connection test** (no video generation)
- [README.md](mdc:packages/providers/fal/video/README.md) - Complete FAL AI dual-model documentation
- [COST_CONSCIOUS_TESTING.md](mdc:packages/providers/fal/video/COST_CONSCIOUS_TESTING.md) - Cost-conscious testing guide

### FAL AI Text-to-Video Generation (NEW)
Located in [packages/providers/fal/text-to-video/](mdc:packages/providers/fal/text-to-video) directory with direct text-to-video generation supporting multiple model options.

**Key Components:**
- [fal_text_to_video_generator.py](mdc:packages/providers/fal/text-to-video/fal_text_to_video_generator.py) - Main FALTextToVideoGenerator class with dual-model support
- [demo.py](mdc:packages/providers/fal/text-to-video/demo.py) - Cost-conscious interactive demo with model selection
- [test_setup.py](mdc:packages/providers/fal/text-to-video/test_setup.py) - **FREE environment and API validation**
- [test_generation.py](mdc:packages/providers/fal/text-to-video/test_generation.py) - **PAID text-to-video generation tests**
- [README.md](mdc:packages/providers/fal/text-to-video/README.md) - Complete FAL AI text-to-video documentation

**Key Features:**
- **MiniMax Hailuo-02 Pro**: 1080p resolution, 6-second duration, $0.08 per video, prompt optimization
- **Google Veo 3**: 720p resolution, 5-8 seconds variable, $2.50-$6.00 per video, audio support
- **Direct Generation**: No image step required - generate videos directly from text
- **Cost-Effective Options**: Choose between cost-effective and premium quality models

### FAL AI Video-to-Video Enhancement (NEW)
Located in [packages/providers/fal/video-to-video/](mdc:packages/providers/fal/video-to-video) directory with AI audio enhancement for existing videos.

**Key Components:**
- [fal_video_to_video/](mdc:packages/providers/fal/video-to-video/fal_video_to_video/) - Main video enhancement package
- [setup.py](mdc:packages/providers/fal/video-to-video/setup.py) - Professional package setup
- [test_topaz_upscale.sh](mdc:packages/providers/fal/video-to-video/test_topaz_upscale.sh) - Video upscaling test script
- [README.md](mdc:packages/providers/fal/video-to-video/README.md) - Complete FAL AI video-to-video documentation
- **Examples:** Usage examples and tutorials for audio enhancement

**Key Features:**
- **ThinkSound API**: AI-powered video audio generation (~$0.001 per second)
- **Text Prompt Audio**: Guide audio generation with natural language descriptions
- **Multiple Formats**: Support for MP4, MOV, AVI, WebM video formats
- **Batch Processing**: Process multiple videos efficiently
- **CLI Interface**: Command-line tools for batch operations

### AI Content Pipeline (NEW)
Located in [packages/core/ai_content_pipeline/](mdc:packages/core/ai_content_pipeline) directory with unified content creation system for chaining AI operations.

**Key Components:**
- [ai_content_pipeline/](mdc:packages/core/ai_content_pipeline/ai_content_pipeline/) - Main pipeline package
- [setup.py](mdc:packages/core/ai_content_pipeline/setup.py) - Professional package setup
- [README.md](mdc:packages/core/ai_content_pipeline/README.md) - Complete AI content pipeline documentation
- **Pipeline Management:**
  - [pipeline/manager.py](mdc:packages/core/ai_content_pipeline/ai_content_pipeline/pipeline/manager.py) - Main pipeline manager
  - [pipeline/chain.py](mdc:packages/core/ai_content_pipeline/ai_content_pipeline/pipeline/chain.py) - Chain configuration classes
  - [pipeline/executor.py](mdc:packages/core/ai_content_pipeline/ai_content_pipeline/pipeline/executor.py) - Chain execution engine
- **Model Integration:**
  - [models/text_to_image.py](mdc:packages/core/ai_content_pipeline/ai_content_pipeline/models/text_to_image.py) - Unified text-to-image generator
  - [models/base.py](mdc:packages/core/ai_content_pipeline/ai_content_pipeline/models/base.py) - Base model interface

**Key Features:**
- **Workflow Chains**: Text → Image → Video → Audio Enhancement → Video Upscaling
- **YAML/JSON Configuration**: Define complex workflows with configuration files
- **Automatic Model Selection**: Choose optimal models based on criteria and budget
- **Cost Optimization**: Transparent pricing and cost estimation for all operations
- **Professional Architecture**: Modular design with proper package structure

### FAL AI Avatar Generation (Triple-Mode)
Located in [packages/providers/fal/avatar/](mdc:packages/providers/fal/avatar) directory with comprehensive avatar video generation using official FAL AI examples.

**Key Components:**
- [fal_avatar_generator.py](mdc:packages/providers/fal/avatar/fal_avatar_generator.py) - Main FALAvatarGenerator class with triple-mode support
- [demo.py](mdc:packages/providers/fal/avatar/demo.py) - Cost-conscious interactive demo with mode selection
- [test_official_example.py](mdc:packages/providers/fal/avatar/test_official_example.py) - **Test using exact FAL AI documentation examples**
- [test_setup.py](mdc:packages/providers/fal/avatar/test_setup.py) - **FREE environment and API validation**
- [test_generation.py](mdc:packages/providers/fal/avatar/test_generation.py) - **PAID avatar generation tests** (includes `--voice`, `--audio`, `--multi` flags)
- [README.md](mdc:packages/providers/fal/avatar/README.md) - Complete FAL AI avatar documentation

### FAL AI Text-to-Image Generation (Quad-Model)
Located in [packages/providers/fal/text-to-image/](mdc:packages/providers/fal/text-to-image) directory with consolidated test structure and direct Python API.

**Key Components:**
- [fal_text_to_image_generator.py](mdc:packages/providers/fal/text-to-image/fal_text_to_image_generator.py) - Main FALTextToImageGenerator class
- [demo.py](mdc:packages/providers/fal/text-to-image/demo.py) - Cost-conscious interactive demo
- **Consolidated Test Suite:**
  - [test_setup.py](mdc:packages/providers/fal/text-to-image/test_setup.py) - **FREE environment and API validation**
  - [test_generation.py](mdc:packages/providers/fal/text-to-image/test_generation.py) - **PAID image generation tests** (includes `--dragon` flag)
- [README.md](mdc:packages/providers/fal/text-to-image/README.md) - Complete FAL AI text-to-image documentation

### FAL AI Image-to-Image Generation (Enhancement Pipeline)
Located in [packages/providers/fal/image-to-image/](mdc:packages/providers/fal/image-to-image) directory with comprehensive image transformation capabilities and professional package structure.

**Key Components:**
- [fal_image_to_image/](mdc:packages/providers/fal/image-to-image/fal_image_to_image/) - Main image enhancement package
- [setup.py](mdc:packages/providers/fal/image-to-image/setup.py) - Professional package setup
- [demo.py](mdc:packages/providers/fal/image-to-image/demo.py) - Cost-conscious interactive demo
- **Comprehensive Test Suite:**
  - [tests/](mdc:packages/providers/fal/image-to-image/tests/) - Complete testing framework
- **Documentation:**
  - [README.md](mdc:packages/providers/fal/image-to-image/README.md) - Complete FAL AI image-to-image documentation
  - [docs/](mdc:packages/providers/fal/image-to-image/docs/) - Detailed documentation
- **Examples:**
  - [examples/](mdc:packages/providers/fal/image-to-image/examples/) - Usage examples and tutorials

**Key Features:**
- **FLUX Image Enhancement**: High-quality image refinement and style transfer
- **Batch Processing**: Multiple image transformations with cost-conscious design
- **Professional Package**: Modular architecture with setup.py and proper testing
- **Multiple Enhancement Modes**: Style transfer, upscaling, and artistic transformations

### ElevenLabs Text-to-Speech Package (Modular Architecture)
Located in [packages/services/text-to-speech/](mdc:packages/services/text-to-speech) directory with comprehensive TTS capabilities and AI content pipeline.

**Key Components:**
- [__init__.py](mdc:packages/services/text-to-speech/__init__.py) - Main package interface with clean imports
- **Core TTS System:**
  - [tts/controller.py](mdc:packages/services/text-to-speech/tts/controller.py) - Main TTS controller class
  - [tts/voice_manager.py](mdc:packages/services/text-to-speech/tts/voice_manager.py) - Voice selection and management (3000+ voices)
  - [tts/audio_processor.py](mdc:packages/services/text-to-speech/tts/audio_processor.py) - Audio format handling and processing
- **AI Content Pipeline:**
  - [pipeline/core.py](mdc:packages/services/text-to-speech/pipeline/core.py) - OpenRouter AI integration with top 10 models
- **Configuration System:**
  - [config/voices.py](mdc:packages/services/text-to-speech/config/voices.py) - Voice presets and configurations
  - [config/models.py](mdc:packages/services/text-to-speech/config/models.py) - AI model settings and recommendations
  - [config/defaults.py](mdc:packages/services/text-to-speech/config/defaults.py) - Default values and settings
- **CLI Tools:**
  - [cli/interactive.py](mdc:packages/services/text-to-speech/cli/interactive.py) - Interactive pipeline interface
  - [cli/quick_start.py](mdc:packages/services/text-to-speech/cli/quick_start.py) - Quick demo runner
- [README.md](mdc:packages/services/text-to-speech/README.md) - Complete package documentation
- [MIGRATION_GUIDE.md](mdc:packages/services/text-to-speech/MIGRATION_GUIDE.md) - Migration from old monolithic structure

**Key Features:**
- **3000+ Voice Library**: Popular presets (Rachel, Drew, Bella) and custom voice cloning
- **AI Content Pipeline**: Generate content using Claude Sonnet 4, Gemini 2.0 Flash, DeepSeek V3, etc.
- **Advanced Voice Control**: Timing, speed control, pause insertion, emotional context tags
- **Multi-Speaker Dialogue**: Natural conversation generation with multiple voices
- **Professional Package**: Modular architecture with setup.py, proper imports, and comprehensive testing

**Supported Video Models:**
- **MiniMax Hailuo-02**: `fal-ai/minimax/hailuo-02/standard/image-to-video`
  - Resolution: 768p
  - Duration: 6-10 seconds
  - Features: Prompt optimizer
- **Kling Video 2.1**: `fal-ai/kling-video/v2.1/standard/image-to-video`
  - Resolution: High-quality
  - Duration: 5-10 seconds
  - Features: CFG scale, negative prompts

**Supported Text-to-Video Models:**
- **MiniMax Hailuo-02 Pro**: `fal-ai/minimax/hailuo-02-pro/text-to-video`
  - Resolution: 1080p
  - Duration: 6 seconds (fixed)
  - Cost: ~$0.08 per video
  - Features: Prompt optimization, commercial use allowed
- **Google Veo 3**: `fal-ai/google/veo-3/text-to-video`
  - Resolution: 720p
  - Duration: 5-8 seconds (variable)
  - Cost: $2.50-$6.00 per video
  - Features: Premium quality, audio support, advanced controls

**Supported Video-to-Video Models:**
- **ThinkSound**: `fal-ai/thinksound/v1/video-to-audio`
  - Cost: ~$0.001 per second of video
  - Features: AI-powered audio generation, text prompt guidance
  - Max Duration: 300 seconds (5 minutes)
  - Output Format: MP4 with enhanced audio

**Supported Avatar Models:**
- **FAL AI Avatar Single-Text**: `fal-ai/ai-avatar/single-text`
  - Features: 20 voice options, text-to-speech conversion, natural lip-sync
  - Frame Range: 81-129 frames (default: 136)
  - Official Example: Bill voice with podcast-style prompt
- **FAL AI Avatar Audio**: `fal-ai/ai-avatar`
  - Features: Custom audio lip-sync, natural expressions
  - Frame Range: 81-129 frames (default: 145)
  - Supports: MP3, WAV, and other audio formats
- **FAL AI Avatar Multi**: `fal-ai/ai-avatar/multi`
  - Features: Two-person conversations, sequential speaking
  - Frame Range: 81-129 frames (default: 181)
  - Supports: Multiple audio files for conversation flow

**Supported Text-to-Image Models:**
- **Imagen4**: `fal-ai/google/imagen4/text-to-image` - Photorealistic, ~6-8s, $0.015/image
- **Seedream**: `fal-ai/seedream/text-to-image` - Artistic style, ~9-15s, $0.015/image
- **FLUX Schnell**: `fal-ai/flux/schnell` - Ultra-fast, ~1-2s, $0.015/image
- **FLUX Dev**: `fal-ai/flux/dev` - Balanced quality, ~2-3s, $0.015/image

## Project Structure
```
veo3/
├── README.md                        # Multi-platform project overview
├── requirements.txt                 # Main dependencies
├── setup.py                         # Unified package setup
├── .env                            # Unified configuration file
├── packages/                        # Main package directory
│   ├── core/                       # Core functionality
│   │   └── ai_content_pipeline/    # Unified AI content pipeline
│   │       ├── ai_content_pipeline/ # Main pipeline package
│   │       │   ├── config/         # Configuration management
│   │       │   ├── models/         # Model implementations
│   │       │   ├── pipeline/       # Pipeline management
│   │       │   └── utils/          # File management and validation
│   │       ├── setup.py            # Professional package setup
│   │       ├── README.md           # AI content pipeline documentation
│   │       ├── requirements.txt    # Pipeline dependencies
│   │       ├── input/              # Input files for pipeline operations
│   │       ├── output/             # Generated content from pipelines
│   │       ├── temp/               # Temporary files during chain execution
│   │       ├── examples/           # Usage examples and chain configurations
│   │       └── tests/              # Complete testing framework
│   ├── providers/                  # AI service providers
│   │   ├── google/                 # Google services
│   │   │   └── veo/                # Google Veo video generation
│   │   │       ├── veo_video_generation.py # Main Google Veo functions
│   │   │       ├── fix_permissions.py # Automated permission fix tool
│   │   │       ├── demo.py         # Interactive Veo demo (2.0/3.0)
│   │   │       ├── test_veo.py     # Comprehensive test suite
│   │   │       ├── README.md       # Veo-specific documentation
│   │   │       ├── requirements.txt # Veo dependencies
│   │   │       ├── .env            # Veo configuration
│   │   │       ├── images/         # Input images
│   │   │       └── result_folder/  # Veo output videos
│   │   └── fal/                    # FAL AI services
│   │       ├── video/              # FAL AI video generation (dual-model)
│   │       │   ├── fal_video_generator.py # FAL AI video generator class
│   │       │   ├── demo.py         # Cost-conscious interactive demo
│   │       │   ├── test_fal_ai.py  # Cost-conscious test suite
│   │       │   ├── test_api_only.py # FREE API connection test
│   │       │   ├── README.md       # FAL AI dual-model documentation
│   │       │   ├── COST_CONSCIOUS_TESTING.md # Cost-conscious testing guide
│   │       │   ├── requirements.txt # FAL AI dependencies
│   │       │   ├── .env.example    # FAL AI configuration template
│   │       │   └── output/         # FAL AI generated videos
│   │       ├── text-to-video/      # FAL AI text-to-video implementation
│   │       │   ├── fal_text_to_video_generator.py # FAL AI text-to-video generator class
│   │       │   ├── demo.py         # Cost-conscious interactive demo
│   │       │   ├── test_setup.py   # FREE environment and API validation
│   │       │   ├── test_generation.py # PAID text-to-video generation tests
│   │       │   ├── README.md       # FAL AI text-to-video documentation
│   │       │   ├── requirements.txt # FAL AI dependencies
│   │       │   ├── .env.example    # FAL AI configuration template
│   │       │   └── output/         # Generated text-to-video files
│   │       ├── video-to-video/     # FAL AI video-to-video enhancement
│   │       │   ├── fal_video_to_video/ # Main video enhancement package
│   │       │   ├── test_topaz_upscale.sh # Video upscaling test script
│   │       │   ├── setup.py        # Professional package setup
│   │       │   ├── README.md       # FAL AI video-to-video documentation
│   │       │   ├── requirements.txt # FAL AI dependencies
│   │       │   ├── .env            # FAL AI configuration
│   │       │   ├── input/          # Input videos for enhancement
│   │       │   ├── output/         # Enhanced videos with AI audio
│   │       │   ├── examples/       # Usage examples and tutorials
│   │       │   ├── docs/           # Detailed documentation
│   │       │   ├── tests/          # Complete testing framework
│   │       │   └── test_output/    # Test-generated enhanced videos
│   │       ├── avatar/             # FAL AI triple-mode avatar implementation
│   │       │   ├── fal_avatar_generator.py # FAL AI avatar generator class
│   │       │   ├── demo.py         # Cost-conscious interactive demo
│   │       │   ├── test_official_example.py # Test using exact FAL AI documentation
│   │       │   ├── test_setup.py   # FREE environment and API validation
│   │       │   ├── test_generation.py # PAID avatar generation tests
│   │       │   ├── README.md       # FAL AI avatar documentation
│   │       │   ├── requirements.txt # FAL AI dependencies
│   │       │   ├── .env            # FAL AI configuration
│   │       │   ├── output/         # Generated avatar videos
│   │       │   └── test_output/    # Test-generated avatar videos
│   │       ├── text-to-image/      # FAL AI quad-model text-to-image implementation
│   │       │   ├── fal_text_to_image_generator.py # FAL AI text-to-image generator class
│   │       │   ├── demo.py         # Cost-conscious interactive demo
│   │       │   ├── test_setup.py   # FREE environment and API validation
│   │       │   ├── test_generation.py # PAID image generation tests
│   │       │   ├── README.md       # FAL AI text-to-image documentation
│   │       │   ├── requirements.txt # FAL AI dependencies
│   │       │   ├── .env            # FAL AI configuration
│   │       │   ├── .gitignore      # Ignore generated images and outputs
│   │       │   ├── output/         # Generated images
│   │       │   └── test_output/    # Test-generated images
│   │       └── image-to-image/     # FAL AI image enhancement implementation
│   │           ├── fal_image_to_image/ # Main image enhancement package
│   │           ├── setup.py        # Professional package setup
│   │           ├── README.md       # Complete FAL AI image-to-image documentation
│   │           ├── requirements.txt # FAL AI dependencies
│   │           ├── .env            # FAL AI configuration
│   │           ├── input/          # Input images for transformation
│   │           ├── output/         # Enhanced/transformed images
│   │           ├── examples/       # Usage examples and tutorials
│   │           ├── docs/           # Detailed documentation
│   │           ├── tests/          # Complete testing framework
│   │           └── archive/        # Archived transformations
│   └── services/                   # Additional services
│       ├── text-to-speech/         # ElevenLabs TTS package (modular architecture)
│       │   ├── __init__.py         # Main package interface
│       │   ├── setup.py            # Professional package setup
│       │   ├── README.md           # Complete package documentation
│       │   ├── MIGRATION_GUIDE.md  # Migration from old monolithic structure
│       │   ├── requirements.txt    # TTS dependencies
│       │   ├── .env                # ElevenLabs configuration
│       │   ├── .gitignore          # Ignore generated audio and cache
│       │   ├── activate_env.sh     # Environment activation script
│       │   ├── models/             # Data models and enums
│       │   │   ├── common.py       # Shared models (VoiceSettings, AudioFormat)
│       │   │   └── pipeline.py     # Pipeline-specific models
│       │   ├── tts/                # Core TTS functionality
│       │   │   ├── controller.py   # Main TTS controller class
│       │   │   ├── voice_manager.py # Voice selection and management (3000+)
│       │   │   └── audio_processor.py # Audio format handling
│       │   ├── pipeline/           # OpenRouter AI integration
│       │   │   └── core.py         # Complete pipeline orchestration
│       │   ├── config/             # Configuration management
│       │   │   ├── voices.py       # Voice presets and configurations
│       │   │   ├── models.py       # AI model settings and recommendations
│       │   │   └── defaults.py     # Default values and settings
│       │   ├── utils/              # Utility functions
│       │   │   ├── file_manager.py # File operations
│       │   │   ├── api_helpers.py  # API utilities
│       │   │   └── validators.py   # Input validation
│       │   ├── cli/                # Command line tools
│       │   │   ├── interactive.py  # Interactive pipeline interface
│       │   │   └── quick_start.py  # Quick demo runner
│       │   ├── examples/           # Usage examples
│       │   │   └── basic_usage.py  # Basic TTS examples
│       │   ├── dialogue/           # Multi-speaker dialogue features
│       │   └── output/             # Generated audio files
│       └── video-tools/            # Video processing utilities
│           ├── video_audio_utils.py # Video/audio processing functions
│           ├── README.md           # Video tools documentation
│           ├── .gitignore          # Ignore generated videos and audio
│           └── sample_video.*      # Sample files for testing
├── tests/                          # Consolidated test suite
├── docs/                           # Documentation
└── archive/                        # Legacy tools and older versions
```

## Configuration Requirements

### Google Veo Setup
- **Quick Setup**: Run `python fix_permissions.py` (fixes 90% of issues automatically)
- Google Cloud Project ID (configured in [packages/providers/google/veo/.env](mdc:packages/providers/google/veo/.env))
- Google Cloud Storage bucket for output
- Vertex AI API enabled (automated by fix script)
- gcloud CLI authentication

### FAL AI Setup (Simpler)
- FAL AI API key in respective `.env` files:
  - [packages/providers/fal/video/.env.example](mdc:packages/providers/fal/video/.env.example) (copy to `.env`)
  - [packages/providers/fal/avatar/.env](mdc:packages/providers/fal/avatar/.env)  
  - [packages/providers/fal/text-to-image/.env](mdc:packages/providers/fal/text-to-image/.env)
  - [packages/providers/fal/image-to-image/.env](mdc:packages/providers/fal/image-to-image/.env)
- Python dependencies: fal-client, requests, python-dotenv
- Single API key works for all FAL AI models (video, avatar, text-to-image, image-to-image)

### ElevenLabs TTS Setup (Professional Package)
- ElevenLabs API key in [packages/services/text-to-speech/.env](mdc:packages/services/text-to-speech/.env)
- Optional: OpenRouter API key for AI content pipeline
- Package installation: `pip install -r packages/services/text-to-speech/requirements.txt`
- Environment activation: `source packages/services/text-to-speech/activate_env.sh`
- Professional package structure with setup.py and modular imports

## Model Selection Guidelines

### Choose MiniMax Hailuo-02 when:
- You need reliable 768p video generation
- You want AI-powered prompt optimization
- You prefer the established model with proven results

### Choose Kling Video 2.1 when:
- You need high-quality video output
- You want fine control with CFG scale parameters
- You need negative prompt capabilities for better quality control

### Choose Google Veo when:
- You need 1080p resolution
- You want longer videos
- You already use Google Cloud infrastructure

### Choose FAL AI Avatar Generation when:
- You need talking avatars with lip-sync
- You want text-to-speech conversion with 20 voice options
- You need custom audio file lip-sync animation
- You want multi-person conversation videos
- You need natural facial expressions and movements

### Choose FAL AI Image-to-Image when:
- You need image enhancement and style transfer
- You want to refine or transform existing images
- You need batch processing of multiple images
- You want professional-grade image modifications with FLUX models
- You need upscaling or artistic transformations

### Choose ElevenLabs TTS when:
- You need high-quality text-to-speech with 3000+ voices
- You want AI-generated content with automatic speech conversion
- You need multi-speaker dialogue and conversation generation
- You want advanced voice control (timing, emotional tags, custom cloning)
- You need a complete AI content pipeline from text generation to audio

## Usage Recommendations

### Video Generation
- **Testing Setup**: Use `python test_api_only.py` for FREE API validation
- **Prototyping**: Start with FAL AI single model testing (`--hailuo` or `--kling`) to avoid unnecessary costs
- **Production**: Use FAL AI for API-based deployments, Google Veo for high-resolution needs
- **Comparison**: Use cost-conscious comparison tools - remember comparison tests generate 2 videos (~$0.04-0.10)

### Avatar Generation
- **Testing Setup**: Use `python test_setup.py` for FREE environment validation
- **Official Testing**: Use `python test_official_example.py` for exact FAL AI documentation examples
- **Prototyping**: Start with single mode testing (`python test_generation.py --voice Bill`) to avoid unnecessary costs
- **Voice Testing**: Use `python test_generation.py --voice [VoiceName]` for specific voice testing (~$0.03-0.05)
- **Audio Testing**: Use `python test_generation.py --audio` for custom audio file testing (~$0.03-0.05)
- **Conversation Testing**: Use `python test_generation.py --multi` for multi-person conversation testing (~$0.03-0.05)
- **Production**: Use official examples as defaults, customize parameters as needed

### Text-to-Image Generation
- **Testing Setup**: Use `python test_setup.py` for FREE environment validation
- **Prototyping**: Start with single model testing (`python test_generation.py --flux-schnell`) to avoid unnecessary costs
- **Dragon Generation**: Use `python test_generation.py --dragon` for dragon image testing (~$0.015)
- **Production**: Use batch generation for efficiency (`python test_generation.py --batch 1,3`)
- **Comparison**: Use comparison tools carefully - remember comparison tests generate 4 images (~$0.060)

### Image-to-Image Generation
- **Testing Setup**: Use `python tests/test_setup.py` for FREE environment validation
- **Prototyping**: Start with single image transformations to avoid unnecessary costs
- **Batch Processing**: Use batch transformation features for multiple images
- **Enhancement**: Focus on specific enhancement modes (style transfer, upscaling, artistic)
- **Production**: Use professional package structure with proper imports and testing
- **Monitor costs** - each image transformation costs vary by complexity

### Text-to-Speech Generation
- **Package Testing**: Use `python -c "from text_to_speech import ElevenLabsTTSController; print('✅ Package working!')"` for FREE import validation
- **Quick Start**: Use `python cli/quick_start.py` for interactive demos and basic testing
- **Interactive Pipeline**: Use `python cli/interactive.py` for full AI content generation pipeline
- **Basic TTS**: Use `python examples/basic_usage.py` for simple text-to-speech examples
- **Voice Testing**: Test specific voices before production use with dummy API keys for structure validation
- **AI Pipeline**: Combine OpenRouter AI content generation with TTS for complete automation
- **Production**: Use modular imports (`from text_to_speech import ElevenLabsTTSController`) for clean integration

## ⚠️ CRITICAL: Cost Protection Rules
**See [cost-protection.mdc](mdc:.cursor/rules/cost-protection.mdc) for complete cost protection guidelines**

### Video Generation
- **NEVER run video generation tests without explicit user confirmation**
- **Always start with FREE tests** (`test_api_only.py`) to validate setup
- **Use model-specific flags** (`--hailuo`, `--kling`) to test individual models
- **Avoid comparison tests** during development unless specifically needed
- **Monitor costs** - each video generation costs ~$0.02-0.05

### Avatar Generation
- **NEVER run avatar generation tests without explicit user confirmation**
- **Always start with FREE tests** (`test_setup.py`) to validate setup
- **Use official examples** (`test_official_example.py`) for documentation compliance
- **Use mode-specific flags** (`--voice`, `--audio`, `--multi`) to test individual modes
- **Avoid comparison tests** during development unless specifically needed
- **Monitor costs** - each avatar generation costs ~$0.02-0.05

### Text-to-Image Generation
- **NEVER run image generation tests without explicit user confirmation**
- **Always start with FREE tests** (`test_setup.py`) to validate setup
- **Use model-specific flags** (`--imagen4`, `--seedream`, `--flux-schnell`, `--flux-dev`) to test individual models
- **Use dragon generation** (`--dragon`) for testing specific scenarios
- **Avoid comparison tests** (`--compare`) during development unless specifically needed
- **Monitor costs** - each image generation costs ~$0.015

### Image-to-Image Generation
- **NEVER run image transformation tests without explicit user confirmation**
- **Always start with FREE tests** (`python tests/test_setup.py`) to validate setup
- **Use professional package structure** with proper imports and testing framework
- **Start with single transformations** before batch processing
- **Monitor costs** - each image transformation costs vary by complexity and model
- **Use examples** (`python -m examples.basic_usage`) for testing structure

### Text-to-Speech Generation
- **Always validate package structure first** with FREE import tests before API calls
- **Use dummy API keys** for development and structure testing
- **Monitor ElevenLabs costs** - speech generation costs vary by character count and voice quality
- **OpenRouter AI costs** - AI content generation costs vary by model (Claude Sonnet 4, Gemini 2.0 Flash, etc.)
- **Start with basic examples** before using advanced AI pipeline features
- **Test voice selection** with short text samples before long-form content














