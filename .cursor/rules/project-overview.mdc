# AI Content Generation Project Overview

This project provides Python utilities for generating videos, images, and avatars using multiple AI platforms:

## Video Generation
1. **Google Veo API** on Vertex AI (higher resolution, automated setup with permission fixes)
2. **FAL AI Dual Models** (simpler setup, production ready)
   - **MiniMax Hailuo-02** (768p, prompt optimizer)
   - **Kling Video 2.1** (high-quality, CFG scale, negative prompts)
3. **NEW: FAL AI Text-to-Video** (direct text-to-video generation)
   - **MiniMax Hailuo-02 Pro** (1080p, $0.08/video, 6s duration)
   - **Google Veo 3** ($2.50-$6.00/video, 720p, 5-8s, audio support)

## Video Enhancement
4. **NEW: FAL AI Video-to-Video** (AI audio enhancement)
   - **ThinkSound API** (~$0.001/second, realistic audio generation)
   - **Text Prompts** (guide audio generation with natural language)
   - **Multiple Formats** (MP4, MOV, AVI, WebM support)

## Avatar Generation
5. **FAL AI Triple-Mode System** (talking avatars with lip-sync)
   - **Text-to-Speech**: 20 voice options with natural speech conversion
   - **Audio-to-Avatar**: Custom audio files for lip-sync animation
   - **Multi-Audio Conversation**: Two-person conversations with sequential speaking

## Text-to-Image Generation
6. **FAL AI Quad Models** (consolidated test structure, direct Python API)
   - **Imagen4** (Google's high-quality model)
   - **Seedream** (Artistic and creative generation)
   - **FLUX Schnell** (Ultra-fast generation)
   - **FLUX Dev** (Balanced speed and quality)

## Image-to-Image Generation
7. **FAL AI Image Enhancement** (comprehensive image transformation pipeline)
   - **FLUX Image Enhancement**: High-quality image refinement and style transfer
   - **Batch Processing**: Multiple image transformations with cost-conscious design
   - **Professional Package**: Modular architecture with setup.py and proper testing

## Text-to-Speech Generation
8. **ElevenLabs TTS Package** (modular architecture, comprehensive features)
   - **3000+ Voice Library**: Popular presets and custom voice cloning
   - **AI Content Pipeline**: OpenRouter AI integration with top 10 models
   - **Advanced Features**: Timing control, multi-speaker dialogue, emotional tags
   - **Professional Package**: Modular design with setup.py and proper imports

## Unified Content Pipeline
9. **NEW: AI Content Pipeline** (chain multiple AI operations)
   - **Text â†’ Image â†’ Video â†’ Audio Enhancement â†’ Video Upscaling**
   - **YAML/JSON Configuration**: Define complex workflows
   - **Automatic Model Selection**: Based on criteria and budget
   - **Cost Optimization**: Transparent pricing and estimation

## Main Components

### Google Veo Implementation
Located in [veo3_video_generation/](mdc:veo3_video_generation) directory with automated setup and permission fixes.

**Key Components:**
- [veo_video_generation.py](mdc:veo3_video_generation/veo_video_generation.py) - Main Google Veo video generation functions
- [fix_permissions.py](mdc:veo3_video_generation/fix_permissions.py) - **Automated permission fix tool** (fixes 90% of setup issues)
- [demo.py](mdc:veo3_video_generation/demo.py) - Interactive demonstration with Veo 2.0/3.0 selection
- [test_veo.py](mdc:veo3_video_generation/test_veo.py) - Comprehensive test suite with command-line options

**Key Functions:**
- `generate_video_from_text()` - Creates videos from text prompts
- `generate_video_from_image()` - Creates videos from images with optional text guidance
- `generate_video_from_local_image()` - Handles local image uploads to GCS
- `generate_video_with_veo3_preview()` - Uses the newer Veo 3.0 model
- `download_gcs_file()` - Downloads generated videos from Google Cloud Storage

**Quick Setup**: Run `python fix_permissions.py` to automatically configure Google Cloud permissions

### FAL AI Video Generation (Dual-Model)
Located in [fal_image_to_video/](mdc:fal_image_to_video) directory with simplified API-based approach supporting two models and cost-conscious testing.

**Key Components:**
- [fal_image_to_video_generator.py](mdc:fal_image_to_video/fal_image_to_video_generator.py) - Main FALImageToVideoGenerator class with full endpoint names
- [demo.py](mdc:fal_image_to_video/demo.py) - Cost-conscious interactive demo with confirmation prompts
- [test_fal_ai.py](mdc:fal_image_to_video/test_fal_ai.py) - Cost-conscious test suite with model-specific flags
- [test_api_only.py](mdc:fal_image_to_video/test_api_only.py) - **FREE API connection test** (no video generation)
- [README.md](mdc:fal_image_to_video/README.md) - Complete FAL AI dual-model documentation
- [COST_CONSCIOUS_TESTING.md](mdc:fal_image_to_video/COST_CONSCIOUS_TESTING.md) - Cost-conscious testing guide

### FAL AI Text-to-Video Generation (NEW)
Located in [fal_text_to_video/](mdc:fal_text_to_video) directory with direct text-to-video generation supporting multiple model options.

**Key Components:**
- [fal_text_to_video_generator.py](mdc:fal_text_to_video/fal_text_to_video_generator.py) - Main FALTextToVideoGenerator class with dual-model support
- [demo.py](mdc:fal_text_to_video/demo.py) - Cost-conscious interactive demo with model selection
- [test_setup.py](mdc:fal_text_to_video/test_setup.py) - **FREE environment and API validation**
- [test_generation.py](mdc:fal_text_to_video/test_generation.py) - **PAID text-to-video generation tests**
- [README.md](mdc:fal_text_to_video/README.md) - Complete FAL AI text-to-video documentation

**Key Features:**
- **MiniMax Hailuo-02 Pro**: 1080p resolution, 6-second duration, $0.08 per video, prompt optimization
- **Google Veo 3**: 720p resolution, 5-8 seconds variable, $2.50-$6.00 per video, audio support
- **Direct Generation**: No image step required - generate videos directly from text
- **Cost-Effective Options**: Choose between cost-effective and premium quality models

### FAL AI Video-to-Video Enhancement (NEW)
Located in [fal_video_to_video/](mdc:fal_video_to_video) directory with AI audio enhancement for existing videos.

**Key Components:**
- [fal_video_to_video/](mdc:fal_video_to_video/fal_video_to_video/) - Main video enhancement package
- [setup.py](mdc:fal_video_to_video/setup.py) - Professional package setup
- [test_topaz_upscale.sh](mdc:fal_video_to_video/test_topaz_upscale.sh) - Video upscaling test script
- [README.md](mdc:fal_video_to_video/README.md) - Complete FAL AI video-to-video documentation
- **Examples:** Usage examples and tutorials for audio enhancement

**Key Features:**
- **ThinkSound API**: AI-powered video audio generation (~$0.001 per second)
- **Text Prompt Audio**: Guide audio generation with natural language descriptions
- **Multiple Formats**: Support for MP4, MOV, AVI, WebM video formats
- **Batch Processing**: Process multiple videos efficiently
- **CLI Interface**: Command-line tools for batch operations

### AI Content Pipeline (NEW)
Located in [ai_content_pipeline/](mdc:ai_content_pipeline) directory with unified content creation system for chaining AI operations.

**Key Components:**
- [ai_content_pipeline/](mdc:ai_content_pipeline/ai_content_pipeline/) - Main pipeline package
- [setup.py](mdc:ai_content_pipeline/setup.py) - Professional package setup
- [README.md](mdc:ai_content_pipeline/README.md) - Complete AI content pipeline documentation
- **Pipeline Management:**
  - [pipeline/manager.py](mdc:ai_content_pipeline/ai_content_pipeline/pipeline/manager.py) - Main pipeline manager
  - [pipeline/chain.py](mdc:ai_content_pipeline/ai_content_pipeline/pipeline/chain.py) - Chain configuration classes
  - [pipeline/executor.py](mdc:ai_content_pipeline/ai_content_pipeline/pipeline/executor.py) - Chain execution engine
- **Model Integration:**
  - [models/text_to_image.py](mdc:ai_content_pipeline/ai_content_pipeline/models/text_to_image.py) - Unified text-to-image generator
  - [models/base.py](mdc:ai_content_pipeline/ai_content_pipeline/models/base.py) - Base model interface

**Key Features:**
- **Workflow Chains**: Text â†’ Image â†’ Video â†’ Audio Enhancement â†’ Video Upscaling
- **YAML/JSON Configuration**: Define complex workflows with configuration files
- **Automatic Model Selection**: Choose optimal models based on criteria and budget
- **Cost Optimization**: Transparent pricing and cost estimation for all operations
- **Professional Architecture**: Modular design with proper package structure

### FAL AI Avatar Generation (Triple-Mode)
Located in [fal_avatar_generation/](mdc:fal_avatar_generation) directory with comprehensive avatar video generation using official FAL AI examples.

**Key Components:**
- [fal_avatar_generator.py](mdc:fal_avatar_generation/fal_avatar_generator.py) - Main FALAvatarGenerator class with triple-mode support
- [demo.py](mdc:fal_avatar_generation/demo.py) - Cost-conscious interactive demo with mode selection
- [test_official_example.py](mdc:fal_avatar_generation/test_official_example.py) - **Test using exact FAL AI documentation examples**
- [test_setup.py](mdc:fal_avatar_generation/test_setup.py) - **FREE environment and API validation**
- [test_generation.py](mdc:fal_avatar_generation/test_generation.py) - **PAID avatar generation tests** (includes `--voice`, `--audio`, `--multi` flags)
- [README.md](mdc:fal_avatar_generation/README.md) - Complete FAL AI avatar documentation

### FAL AI Text-to-Image Generation (Quad-Model)
Located in [fal_text_to_image/](mdc:fal_text_to_image) directory with consolidated test structure and direct Python API.

**Key Components:**
- [fal_text_to_image_generator.py](mdc:fal_text_to_image/fal_text_to_image_generator.py) - Main FALTextToImageGenerator class
- [demo.py](mdc:fal_text_to_image/demo.py) - Cost-conscious interactive demo
- **Consolidated Test Suite:**
  - [test_setup.py](mdc:fal_text_to_image/test_setup.py) - **FREE environment and API validation**
  - [test_generation.py](mdc:fal_text_to_image/test_generation.py) - **PAID image generation tests** (includes `--dragon` flag)
- [README.md](mdc:fal_text_to_image/README.md) - Complete FAL AI text-to-image documentation

### FAL AI Image-to-Image Generation (Enhancement Pipeline)
Located in [fal_image_to_image/](mdc:fal_image_to_image) directory with comprehensive image transformation capabilities and professional package structure.

**Key Components:**
- [fal_image_to_image/](mdc:fal_image_to_image/fal_image_to_image/) - Main image enhancement package
- [setup.py](mdc:fal_image_to_image/setup.py) - Professional package setup
- [demo.py](mdc:fal_image_to_image/demo.py) - Cost-conscious interactive demo
- **Comprehensive Test Suite:**
  - [tests/](mdc:fal_image_to_image/tests/) - Complete testing framework
- **Documentation:**
  - [README.md](mdc:fal_image_to_image/README.md) - Complete FAL AI image-to-image documentation
  - [docs/](mdc:fal_image_to_image/docs/) - Detailed documentation
- **Examples:**
  - [examples/](mdc:fal_image_to_image/examples/) - Usage examples and tutorials

**Key Features:**
- **FLUX Image Enhancement**: High-quality image refinement and style transfer
- **Batch Processing**: Multiple image transformations with cost-conscious design
- **Professional Package**: Modular architecture with setup.py and proper testing
- **Multiple Enhancement Modes**: Style transfer, upscaling, and artistic transformations

### ElevenLabs Text-to-Speech Package (Modular Architecture)
Located in [text_to_speech/](mdc:text_to_speech) directory with comprehensive TTS capabilities and AI content pipeline.

**Key Components:**
- [__init__.py](mdc:text_to_speech/__init__.py) - Main package interface with clean imports
- **Core TTS System:**
  - [tts/controller.py](mdc:text_to_speech/tts/controller.py) - Main TTS controller class
  - [tts/voice_manager.py](mdc:text_to_speech/tts/voice_manager.py) - Voice selection and management (3000+ voices)
  - [tts/audio_processor.py](mdc:text_to_speech/tts/audio_processor.py) - Audio format handling and processing
- **AI Content Pipeline:**
  - [pipeline/core.py](mdc:text_to_speech/pipeline/core.py) - OpenRouter AI integration with top 10 models
- **Configuration System:**
  - [config/voices.py](mdc:text_to_speech/config/voices.py) - Voice presets and configurations
  - [config/models.py](mdc:text_to_speech/config/models.py) - AI model settings and recommendations
  - [config/defaults.py](mdc:text_to_speech/config/defaults.py) - Default values and settings
- **CLI Tools:**
  - [cli/interactive.py](mdc:text_to_speech/cli/interactive.py) - Interactive pipeline interface
  - [cli/quick_start.py](mdc:text_to_speech/cli/quick_start.py) - Quick demo runner
- [README.md](mdc:text_to_speech/README.md) - Complete package documentation
- [MIGRATION_GUIDE.md](mdc:text_to_speech/MIGRATION_GUIDE.md) - Migration from old monolithic structure

**Key Features:**
- **3000+ Voice Library**: Popular presets (Rachel, Drew, Bella) and custom voice cloning
- **AI Content Pipeline**: Generate content using Claude Sonnet 4, Gemini 2.0 Flash, DeepSeek V3, etc.
- **Advanced Voice Control**: Timing, speed control, pause insertion, emotional context tags
- **Multi-Speaker Dialogue**: Natural conversation generation with multiple voices
- **Professional Package**: Modular architecture with setup.py, proper imports, and comprehensive testing

**Supported Video Models:**
- **MiniMax Hailuo-02**: `fal-ai/minimax/hailuo-02/standard/image-to-video`
  - Resolution: 768p
  - Duration: 6-10 seconds
  - Features: Prompt optimizer
- **Kling Video 2.1**: `fal-ai/kling-video/v2.1/standard/image-to-video`
  - Resolution: High-quality
  - Duration: 5-10 seconds
  - Features: CFG scale, negative prompts

**Supported Text-to-Video Models:**
- **MiniMax Hailuo-02 Pro**: `fal-ai/minimax/hailuo-02-pro/text-to-video`
  - Resolution: 1080p
  - Duration: 6 seconds (fixed)
  - Cost: ~$0.08 per video
  - Features: Prompt optimization, commercial use allowed
- **Google Veo 3**: `fal-ai/google/veo-3/text-to-video`
  - Resolution: 720p
  - Duration: 5-8 seconds (variable)
  - Cost: $2.50-$6.00 per video
  - Features: Premium quality, audio support, advanced controls

**Supported Video-to-Video Models:**
- **ThinkSound**: `fal-ai/thinksound/v1/video-to-audio`
  - Cost: ~$0.001 per second of video
  - Features: AI-powered audio generation, text prompt guidance
  - Max Duration: 300 seconds (5 minutes)
  - Output Format: MP4 with enhanced audio

**Supported Avatar Models:**
- **FAL AI Avatar Single-Text**: `fal-ai/ai-avatar/single-text`
  - Features: 20 voice options, text-to-speech conversion, natural lip-sync
  - Frame Range: 81-129 frames (default: 136)
  - Official Example: Bill voice with podcast-style prompt
- **FAL AI Avatar Audio**: `fal-ai/ai-avatar`
  - Features: Custom audio lip-sync, natural expressions
  - Frame Range: 81-129 frames (default: 145)
  - Supports: MP3, WAV, and other audio formats
- **FAL AI Avatar Multi**: `fal-ai/ai-avatar/multi`
  - Features: Two-person conversations, sequential speaking
  - Frame Range: 81-129 frames (default: 181)
  - Supports: Multiple audio files for conversation flow

**Supported Text-to-Image Models:**
- **Imagen4**: `fal-ai/google/imagen4/text-to-image` - Photorealistic, ~6-8s, $0.015/image
- **Seedream**: `fal-ai/seedream/text-to-image` - Artistic style, ~9-15s, $0.015/image
- **FLUX Schnell**: `fal-ai/flux/schnell` - Ultra-fast, ~1-2s, $0.015/image
- **FLUX Dev**: `fal-ai/flux/dev` - Balanced quality, ~2-3s, $0.015/image

## Project Structure
```
veo3/
â”œâ”€â”€ README.md                        # Multi-platform project overview
â”œâ”€â”€ requirements.txt                 # Main dependencies
â”œâ”€â”€ .env                            # Legacy configuration file
â”œâ”€â”€ archive/                         # Legacy tools and older versions
â”œâ”€â”€ veo3_video_generation/           # Google Veo implementation
â”‚   â”œâ”€â”€ veo_video_generation.py     # Main Google Veo functions
â”‚   â”œâ”€â”€ fix_permissions.py          # ğŸ”§ Automated permission fix tool
â”‚   â”œâ”€â”€ demo.py                     # Interactive Veo demo (2.0/3.0)
â”‚   â”œâ”€â”€ test_veo.py                 # Comprehensive test suite
â”‚   â”œâ”€â”€ README.md                   # Veo-specific documentation
â”‚   â”œâ”€â”€ requirements.txt            # Veo dependencies
â”‚   â”œâ”€â”€ .env                        # Veo configuration
â”‚   â”œâ”€â”€ images/                     # Input images (smiling_woman.jpg, bet.png)
â”‚   â””â”€â”€ result_folder/              # Veo output videos
â”œâ”€â”€ fal_image_to_video/              # FAL AI dual-model video implementation
â”‚   â”œâ”€â”€ fal_image_to_video_generator.py # FAL AI image-to-video generator class (dual-model)
â”‚   â”œâ”€â”€ demo.py                      # Cost-conscious interactive demo
â”‚   â”œâ”€â”€ test_fal_ai.py              # Cost-conscious test suite (both models)
â”‚   â”œâ”€â”€ test_api_only.py            # FREE API connection test
â”‚   â”œâ”€â”€ README.md                    # FAL AI dual-model documentation
â”‚   â”œâ”€â”€ COST_CONSCIOUS_TESTING.md   # Cost-conscious testing guide
â”‚   â”œâ”€â”€ requirements.txt             # FAL AI dependencies
â”‚   â”œâ”€â”€ .env.example                 # FAL AI configuration template
â”‚   â””â”€â”€ output/                      # FAL AI generated videos
â”œâ”€â”€ fal_text_to_video/               # NEW: FAL AI text-to-video implementation
â”‚   â”œâ”€â”€ fal_text_to_video_generator.py # FAL AI text-to-video generator class (dual-model)
â”‚   â”œâ”€â”€ demo.py                      # Cost-conscious interactive demo with model selection
â”‚   â”œâ”€â”€ test_setup.py               # FREE environment and API validation
â”‚   â”œâ”€â”€ test_generation.py          # PAID text-to-video generation tests
â”‚   â”œâ”€â”€ README.md                    # FAL AI text-to-video documentation
â”‚   â”œâ”€â”€ requirements.txt             # FAL AI dependencies
â”‚   â”œâ”€â”€ .env.example                 # FAL AI configuration template
â”‚   â””â”€â”€ output/                      # Generated text-to-video files
â”œâ”€â”€ fal_video_to_video/              # NEW: FAL AI video-to-video enhancement
â”‚   â”œâ”€â”€ fal_video_to_video/          # Main video enhancement package
â”‚   â”œâ”€â”€ test_topaz_upscale.sh        # Video upscaling test script
â”‚   â”œâ”€â”€ setup.py                     # Professional package setup
â”‚   â”œâ”€â”€ README.md                    # FAL AI video-to-video documentation
â”‚   â”œâ”€â”€ requirements.txt             # FAL AI dependencies
â”‚   â”œâ”€â”€ .env                         # FAL AI configuration
â”‚   â”œâ”€â”€ input/                       # Input videos for enhancement
â”‚   â”œâ”€â”€ output/                      # Enhanced videos with AI audio
â”‚   â”œâ”€â”€ examples/                    # Usage examples and tutorials
â”‚   â”œâ”€â”€ docs/                        # Detailed documentation
â”‚   â”œâ”€â”€ tests/                       # Complete testing framework
â”‚   â””â”€â”€ test_output/                 # Test-generated enhanced videos
â”œâ”€â”€ ai_content_pipeline/             # NEW: Unified AI content pipeline
â”‚   â”œâ”€â”€ ai_content_pipeline/         # Main pipeline package
â”‚   â”‚   â”œâ”€â”€ config/                 # Configuration management
â”‚   â”‚   â”œâ”€â”€ models/                 # Model implementations (text-to-image, etc.)
â”‚   â”‚   â”œâ”€â”€ pipeline/               # Pipeline management (manager, chain, executor)
â”‚   â”‚   â””â”€â”€ utils/                  # File management and validation
â”‚   â”œâ”€â”€ setup.py                     # Professional package setup
â”‚   â”œâ”€â”€ README.md                    # AI content pipeline documentation
â”‚   â”œâ”€â”€ requirements.txt             # Pipeline dependencies
â”‚   â”œâ”€â”€ input/                       # Input files for pipeline operations
â”‚   â”œâ”€â”€ output/                      # Generated content from pipelines
â”‚   â”œâ”€â”€ temp/                        # Temporary files during chain execution
â”‚   â”œâ”€â”€ examples/                    # Usage examples and chain configurations
â”‚   â””â”€â”€ tests/                       # Complete testing framework
â”œâ”€â”€ fal_avatar_generation/           # FAL AI triple-mode avatar implementation
â”‚   â”œâ”€â”€ fal_avatar_generator.py      # FAL AI avatar generator class (triple-mode)
â”‚   â”œâ”€â”€ demo.py                      # Cost-conscious interactive demo with mode selection
â”‚   â”œâ”€â”€ test_official_example.py    # Test using exact FAL AI documentation examples
â”‚   â”œâ”€â”€ test_setup.py               # FREE environment and API validation
â”‚   â”œâ”€â”€ test_generation.py          # PAID avatar generation tests (voice/audio/multi flags)
â”‚   â”œâ”€â”€ README.md                    # FAL AI avatar documentation
â”‚   â”œâ”€â”€ requirements.txt             # FAL AI dependencies
â”‚   â”œâ”€â”€ .env                         # FAL AI configuration
â”‚   â”œâ”€â”€ output/                      # Generated avatar videos
â”‚   â””â”€â”€ test_output/                 # Test-generated avatar videos
â”œâ”€â”€ fal_text_to_image/               # FAL AI quad-model text-to-image implementation
â”‚   â”œâ”€â”€ fal_text_to_image_generator.py # FAL AI text-to-image generator class
â”‚   â”œâ”€â”€ demo.py                      # Cost-conscious interactive demo
â”‚   â”œâ”€â”€ test_setup.py               # FREE environment and API validation
â”‚   â”œâ”€â”€ test_generation.py          # PAID image generation tests (includes --dragon)
â”‚   â”œâ”€â”€ README.md                    # FAL AI text-to-image documentation
â”‚   â”œâ”€â”€ requirements.txt             # FAL AI dependencies
â”‚   â”œâ”€â”€ .env                         # FAL AI configuration
â”‚   â”œâ”€â”€ .gitignore                   # Ignore generated images and outputs
â”‚   â”œâ”€â”€ output/                      # Generated images
â”‚   â””â”€â”€ test_output/                 # Test-generated images
â”œâ”€â”€ fal_image_to_image/              # FAL AI image enhancement implementation
â”‚   â”œâ”€â”€ fal_image_to_image/          # Main image enhancement package
â”‚   â”œâ”€â”€ setup.py                     # Professional package setup
â”‚   â”œâ”€â”€ README.md                    # Complete FAL AI image-to-image documentation
â”‚   â”œâ”€â”€ requirements.txt             # FAL AI dependencies
â”‚   â”œâ”€â”€ .env                         # FAL AI configuration
â”‚   â”œâ”€â”€ input/                       # Input images for transformation
â”‚   â”œâ”€â”€ output/                      # Enhanced/transformed images
â”‚   â”œâ”€â”€ examples/                    # Usage examples and tutorials
â”‚   â”œâ”€â”€ docs/                        # Detailed documentation
â”‚   â”œâ”€â”€ tests/                       # Complete testing framework
â”‚   â””â”€â”€ archive/                     # Archived transformations
â”œâ”€â”€ text_to_speech/                  # ElevenLabs TTS package (modular architecture)
â”‚   â”œâ”€â”€ __init__.py                  # Main package interface
â”‚   â”œâ”€â”€ setup.py                     # Professional package setup
â”‚   â”œâ”€â”€ README.md                    # Complete package documentation
â”‚   â”œâ”€â”€ MIGRATION_GUIDE.md          # Migration from old monolithic structure
â”‚   â”œâ”€â”€ requirements.txt             # TTS dependencies
â”‚   â”œâ”€â”€ .env                         # ElevenLabs configuration
â”‚   â”œâ”€â”€ .gitignore                   # Ignore generated audio and cache
â”‚   â”œâ”€â”€ activate_env.sh             # Environment activation script
â”‚   â”œâ”€â”€ models/                      # Data models and enums
â”‚   â”‚   â”œâ”€â”€ common.py               # Shared models (VoiceSettings, AudioFormat)
â”‚   â”‚   â””â”€â”€ pipeline.py             # Pipeline-specific models
â”‚   â”œâ”€â”€ tts/                         # Core TTS functionality
â”‚   â”‚   â”œâ”€â”€ controller.py           # Main TTS controller class
â”‚   â”‚   â”œâ”€â”€ voice_manager.py        # Voice selection and management (3000+)
â”‚   â”‚   â””â”€â”€ audio_processor.py      # Audio format handling
â”‚   â”œâ”€â”€ pipeline/                    # OpenRouter AI integration
â”‚   â”‚   â””â”€â”€ core.py                 # Complete pipeline orchestration
â”‚   â”œâ”€â”€ config/                      # Configuration management
â”‚   â”‚   â”œâ”€â”€ voices.py               # Voice presets and configurations
â”‚   â”‚   â”œâ”€â”€ models.py               # AI model settings and recommendations
â”‚   â”‚   â””â”€â”€ defaults.py             # Default values and settings
â”‚   â”œâ”€â”€ utils/                       # Utility functions
â”‚   â”‚   â”œâ”€â”€ file_manager.py         # File operations
â”‚   â”‚   â”œâ”€â”€ api_helpers.py          # API utilities
â”‚   â”‚   â””â”€â”€ validators.py           # Input validation
â”‚   â”œâ”€â”€ cli/                         # Command line tools
â”‚   â”‚   â”œâ”€â”€ interactive.py          # Interactive pipeline interface
â”‚   â”‚   â””â”€â”€ quick_start.py          # Quick demo runner
â”‚   â”œâ”€â”€ examples/                    # Usage examples
â”‚   â”‚   â””â”€â”€ basic_usage.py          # Basic TTS examples
â”‚   â”œâ”€â”€ dialogue/                    # Multi-speaker dialogue features
â”‚   â””â”€â”€ output/                      # Generated audio files
â””â”€â”€ video_tools/                     # Video processing utilities
    â”œâ”€â”€ video_audio_utils.py         # Video/audio processing functions
    â”œâ”€â”€ README.md                    # Video tools documentation
    â”œâ”€â”€ .gitignore                   # Ignore generated videos and audio
    â””â”€â”€ sample_video.*               # Sample files for testing
```

## Configuration Requirements

### Google Veo Setup
- **Quick Setup**: Run `python fix_permissions.py` (fixes 90% of issues automatically)
- Google Cloud Project ID (configured in [veo3_video_generation/.env](mdc:veo3_video_generation/.env))
- Google Cloud Storage bucket for output
- Vertex AI API enabled (automated by fix script)
- gcloud CLI authentication

### FAL AI Setup (Simpler)
- FAL AI API key in respective `.env` files:
  - [fal_image_to_video/.env.example](mdc:fal_image_to_video/.env.example) (copy to `.env`)
  - [fal_avatar_generation/.env](mdc:fal_avatar_generation/.env)  
  - [fal_text_to_image/.env](mdc:fal_text_to_image/.env)
  - [fal_image_to_image/.env](mdc:fal_image_to_image/.env)
- Python dependencies: fal-client, requests, python-dotenv
- Single API key works for all FAL AI models (video, avatar, text-to-image, image-to-image)

### ElevenLabs TTS Setup (Professional Package)
- ElevenLabs API key in [text_to_speech/.env](mdc:text_to_speech/.env)
- Optional: OpenRouter API key for AI content pipeline
- Package installation: `pip install -r text_to_speech/requirements.txt`
- Environment activation: `source text_to_speech/activate_env.sh`
- Professional package structure with setup.py and modular imports

## Model Selection Guidelines

### Choose MiniMax Hailuo-02 when:
- You need reliable 768p video generation
- You want AI-powered prompt optimization
- You prefer the established model with proven results

### Choose Kling Video 2.1 when:
- You need high-quality video output
- You want fine control with CFG scale parameters
- You need negative prompt capabilities for better quality control

### Choose Google Veo when:
- You need 1080p resolution
- You want longer videos
- You already use Google Cloud infrastructure

### Choose FAL AI Avatar Generation when:
- You need talking avatars with lip-sync
- You want text-to-speech conversion with 20 voice options
- You need custom audio file lip-sync animation
- You want multi-person conversation videos
- You need natural facial expressions and movements

### Choose FAL AI Image-to-Image when:
- You need image enhancement and style transfer
- You want to refine or transform existing images
- You need batch processing of multiple images
- You want professional-grade image modifications with FLUX models
- You need upscaling or artistic transformations

### Choose ElevenLabs TTS when:
- You need high-quality text-to-speech with 3000+ voices
- You want AI-generated content with automatic speech conversion
- You need multi-speaker dialogue and conversation generation
- You want advanced voice control (timing, emotional tags, custom cloning)
- You need a complete AI content pipeline from text generation to audio

## Usage Recommendations

### Video Generation
- **Testing Setup**: Use `python test_api_only.py` for FREE API validation
- **Prototyping**: Start with FAL AI single model testing (`--hailuo` or `--kling`) to avoid unnecessary costs
- **Production**: Use FAL AI for API-based deployments, Google Veo for high-resolution needs
- **Comparison**: Use cost-conscious comparison tools - remember comparison tests generate 2 videos (~$0.04-0.10)

### Avatar Generation
- **Testing Setup**: Use `python test_setup.py` for FREE environment validation
- **Official Testing**: Use `python test_official_example.py` for exact FAL AI documentation examples
- **Prototyping**: Start with single mode testing (`python test_generation.py --voice Bill`) to avoid unnecessary costs
- **Voice Testing**: Use `python test_generation.py --voice [VoiceName]` for specific voice testing (~$0.03-0.05)
- **Audio Testing**: Use `python test_generation.py --audio` for custom audio file testing (~$0.03-0.05)
- **Conversation Testing**: Use `python test_generation.py --multi` for multi-person conversation testing (~$0.03-0.05)
- **Production**: Use official examples as defaults, customize parameters as needed

### Text-to-Image Generation
- **Testing Setup**: Use `python test_setup.py` for FREE environment validation
- **Prototyping**: Start with single model testing (`python test_generation.py --flux-schnell`) to avoid unnecessary costs
- **Dragon Generation**: Use `python test_generation.py --dragon` for dragon image testing (~$0.015)
- **Production**: Use batch generation for efficiency (`python test_generation.py --batch 1,3`)
- **Comparison**: Use comparison tools carefully - remember comparison tests generate 4 images (~$0.060)

### Image-to-Image Generation
- **Testing Setup**: Use `python tests/test_setup.py` for FREE environment validation
- **Prototyping**: Start with single image transformations to avoid unnecessary costs
- **Batch Processing**: Use batch transformation features for multiple images
- **Enhancement**: Focus on specific enhancement modes (style transfer, upscaling, artistic)
- **Production**: Use professional package structure with proper imports and testing
- **Monitor costs** - each image transformation costs vary by complexity

### Text-to-Speech Generation
- **Package Testing**: Use `python -c "from text_to_speech import ElevenLabsTTSController; print('âœ… Package working!')"` for FREE import validation
- **Quick Start**: Use `python cli/quick_start.py` for interactive demos and basic testing
- **Interactive Pipeline**: Use `python cli/interactive.py` for full AI content generation pipeline
- **Basic TTS**: Use `python examples/basic_usage.py` for simple text-to-speech examples
- **Voice Testing**: Test specific voices before production use with dummy API keys for structure validation
- **AI Pipeline**: Combine OpenRouter AI content generation with TTS for complete automation
- **Production**: Use modular imports (`from text_to_speech import ElevenLabsTTSController`) for clean integration

## âš ï¸ CRITICAL: Cost Protection Rules
**See [cost-protection.mdc](mdc:.cursor/rules/cost-protection.mdc) for complete cost protection guidelines**

### Video Generation
- **NEVER run video generation tests without explicit user confirmation**
- **Always start with FREE tests** (`test_api_only.py`) to validate setup
- **Use model-specific flags** (`--hailuo`, `--kling`) to test individual models
- **Avoid comparison tests** during development unless specifically needed
- **Monitor costs** - each video generation costs ~$0.02-0.05

### Avatar Generation
- **NEVER run avatar generation tests without explicit user confirmation**
- **Always start with FREE tests** (`test_setup.py`) to validate setup
- **Use official examples** (`test_official_example.py`) for documentation compliance
- **Use mode-specific flags** (`--voice`, `--audio`, `--multi`) to test individual modes
- **Avoid comparison tests** during development unless specifically needed
- **Monitor costs** - each avatar generation costs ~$0.02-0.05

### Text-to-Image Generation
- **NEVER run image generation tests without explicit user confirmation**
- **Always start with FREE tests** (`test_setup.py`) to validate setup
- **Use model-specific flags** (`--imagen4`, `--seedream`, `--flux-schnell`, `--flux-dev`) to test individual models
- **Use dragon generation** (`--dragon`) for testing specific scenarios
- **Avoid comparison tests** (`--compare`) during development unless specifically needed
- **Monitor costs** - each image generation costs ~$0.015

### Image-to-Image Generation
- **NEVER run image transformation tests without explicit user confirmation**
- **Always start with FREE tests** (`python tests/test_setup.py`) to validate setup
- **Use professional package structure** with proper imports and testing framework
- **Start with single transformations** before batch processing
- **Monitor costs** - each image transformation costs vary by complexity and model
- **Use examples** (`python -m examples.basic_usage`) for testing structure

### Text-to-Speech Generation
- **Always validate package structure first** with FREE import tests before API calls
- **Use dummy API keys** for development and structure testing
- **Monitor ElevenLabs costs** - speech generation costs vary by character count and voice quality
- **OpenRouter AI costs** - AI content generation costs vary by model (Claude Sonnet 4, Gemini 2.0 Flash, etc.)
- **Start with basic examples** before using advanced AI pipeline features
- **Test voice selection** with short text samples before long-form content














