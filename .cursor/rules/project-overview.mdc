---
description: 
globs: 
alwaysApply: true
---
# AI Content Generation Project Overview

This project provides Python utilities for generating videos, images, and avatars using multiple AI platforms:

## Video Generation
1. **Google Veo API** on Vertex AI (higher resolution, automated setup with permission fixes)
2. **FAL AI Dual Models** (simpler setup, production ready)
   - **MiniMax Hailuo-02** (768p, prompt optimizer)
   - **Kling Video 2.1** (high-quality, CFG scale, negative prompts)

## Avatar Generation
3. **FAL AI Triple-Mode System** (talking avatars with lip-sync)
   - **Text-to-Speech**: 20 voice options with natural speech conversion
   - **Audio-to-Avatar**: Custom audio files for lip-sync animation
   - **Multi-Audio Conversation**: Two-person conversations with sequential speaking

## Text-to-Image Generation
4. **FAL AI Quad Models** (consolidated test structure, direct Python API)
   - **Imagen4** (Google's high-quality model)
   - **Seedream** (Artistic and creative generation)
   - **FLUX Schnell** (Ultra-fast generation)
   - **FLUX Dev** (Balanced speed and quality)

## Main Components

### Google Veo Implementation
Located in [veo3_video_generation/](mdc:veo3_video_generation) directory with automated setup and permission fixes.

**Key Components:**
- [veo_video_generation.py](mdc:veo3_video_generation/veo_video_generation.py) - Main Google Veo video generation functions
- [fix_permissions.py](mdc:veo3_video_generation/fix_permissions.py) - **Automated permission fix tool** (fixes 90% of setup issues)
- [demo.py](mdc:veo3_video_generation/demo.py) - Interactive demonstration with Veo 2.0/3.0 selection
- [test_veo.py](mdc:veo3_video_generation/test_veo.py) - Comprehensive test suite with command-line options

**Key Functions:**
- `generate_video_from_text()` - Creates videos from text prompts
- `generate_video_from_image()` - Creates videos from images with optional text guidance
- `generate_video_from_local_image()` - Handles local image uploads to GCS
- `generate_video_with_veo3_preview()` - Uses the newer Veo 3.0 model
- `download_gcs_file()` - Downloads generated videos from Google Cloud Storage

**Quick Setup**: Run `python fix_permissions.py` to automatically configure Google Cloud permissions

### FAL AI Video Generation (Dual-Model)
Located in [fal_video_generation/](mdc:fal_video_generation) directory with simplified API-based approach supporting two models and cost-conscious testing.

**Key Components:**
- [fal_video_generator.py](mdc:fal_video_generation/fal_video_generator.py) - Main FALVideoGenerator class with full endpoint names
- [demo.py](mdc:fal_video_generation/demo.py) - Cost-conscious interactive demo with confirmation prompts
- [test_fal_ai.py](mdc:fal_video_generation/test_fal_ai.py) - Cost-conscious test suite with model-specific flags
- [test_api_only.py](mdc:fal_video_generation/test_api_only.py) - **FREE API connection test** (no video generation)
- [README.md](mdc:fal_video_generation/README.md) - Complete FAL AI dual-model documentation
- [COST_CONSCIOUS_TESTING.md](mdc:fal_video_generation/COST_CONSCIOUS_TESTING.md) - Cost-conscious testing guide

### FAL AI Avatar Generation (Triple-Mode)
Located in [fal_avatar_generation/](mdc:fal_avatar_generation) directory with comprehensive avatar video generation using official FAL AI examples.

**Key Components:**
- [fal_avatar_generator.py](mdc:fal_avatar_generation/fal_avatar_generator.py) - Main FALAvatarGenerator class with triple-mode support
- [demo.py](mdc:fal_avatar_generation/demo.py) - Cost-conscious interactive demo with mode selection
- [test_official_example.py](mdc:fal_avatar_generation/test_official_example.py) - **Test using exact FAL AI documentation examples**
- [test_setup.py](mdc:fal_avatar_generation/test_setup.py) - **FREE environment and API validation**
- [test_generation.py](mdc:fal_avatar_generation/test_generation.py) - **PAID avatar generation tests** (includes `--voice`, `--audio`, `--multi` flags)
- [README.md](mdc:fal_avatar_generation/README.md) - Complete FAL AI avatar documentation

### FAL AI Text-to-Image Generation (Quad-Model)
Located in [fal_text_to_image/](mdc:fal_text_to_image) directory with consolidated test structure and direct Python API.

**Key Components:**
- [fal_text_to_image_generator.py](mdc:fal_text_to_image/fal_text_to_image_generator.py) - Main FALTextToImageGenerator class
- [demo.py](mdc:fal_text_to_image/demo.py) - Cost-conscious interactive demo
- **Consolidated Test Suite:**
  - [test_setup.py](mdc:fal_text_to_image/test_setup.py) - **FREE environment and API validation**
  - [test_generation.py](mdc:fal_text_to_image/test_generation.py) - **PAID image generation tests** (includes `--dragon` flag)
- [README.md](mdc:fal_text_to_image/README.md) - Complete FAL AI text-to-image documentation

**Supported Video Models:**
- **MiniMax Hailuo-02**: `fal-ai/minimax/hailuo-02/standard/image-to-video`
  - Resolution: 768p
  - Duration: 6-10 seconds
  - Features: Prompt optimizer
- **Kling Video 2.1**: `fal-ai/kling-video/v2.1/standard/image-to-video`
  - Resolution: High-quality
  - Duration: 5-10 seconds
  - Features: CFG scale, negative prompts

**Supported Avatar Models:**
- **FAL AI Avatar Single-Text**: `fal-ai/ai-avatar/single-text`
  - Features: 20 voice options, text-to-speech conversion, natural lip-sync
  - Frame Range: 81-129 frames (default: 136)
  - Official Example: Bill voice with podcast-style prompt
- **FAL AI Avatar Audio**: `fal-ai/ai-avatar`
  - Features: Custom audio lip-sync, natural expressions
  - Frame Range: 81-129 frames (default: 145)
  - Supports: MP3, WAV, and other audio formats
- **FAL AI Avatar Multi**: `fal-ai/ai-avatar/multi`
  - Features: Two-person conversations, sequential speaking
  - Frame Range: 81-129 frames (default: 181)
  - Supports: Multiple audio files for conversation flow

**Supported Text-to-Image Models:**
- **Imagen4**: `fal-ai/google/imagen4/text-to-image` - Photorealistic, ~6-8s, $0.015/image
- **Seedream**: `fal-ai/seedream/text-to-image` - Artistic style, ~9-15s, $0.015/image
- **FLUX Schnell**: `fal-ai/flux/schnell` - Ultra-fast, ~1-2s, $0.015/image
- **FLUX Dev**: `fal-ai/flux/dev` - Balanced quality, ~2-3s, $0.015/image

## Project Structure
```
veo3/
â”œâ”€â”€ README.md                        # Multi-platform project overview
â”œâ”€â”€ requirements.txt                 # Main dependencies
â”œâ”€â”€ .env                            # Legacy configuration file
â”œâ”€â”€ archive/                         # Legacy tools and older versions
â”œâ”€â”€ veo3_video_generation/           # Google Veo implementation
â”‚   â”œâ”€â”€ veo_video_generation.py     # Main Google Veo functions
â”‚   â”œâ”€â”€ fix_permissions.py          # ğŸ”§ Automated permission fix tool
â”‚   â”œâ”€â”€ demo.py                     # Interactive Veo demo (2.0/3.0)
â”‚   â”œâ”€â”€ test_veo.py                 # Comprehensive test suite
â”‚   â”œâ”€â”€ README.md                   # Veo-specific documentation
â”‚   â”œâ”€â”€ requirements.txt            # Veo dependencies
â”‚   â”œâ”€â”€ .env                        # Veo configuration
â”‚   â”œâ”€â”€ images/                     # Input images (smiling_woman.jpg, bet.png)
â”‚   â””â”€â”€ result_folder/              # Veo output videos
â”œâ”€â”€ fal_video_generation/            # FAL AI dual-model video implementation
â”‚   â”œâ”€â”€ fal_video_generator.py       # FAL AI video generator class (dual-model)
â”‚   â”œâ”€â”€ demo.py                      # Cost-conscious interactive demo
â”‚   â”œâ”€â”€ test_fal_ai.py              # Cost-conscious test suite (both models)
â”‚   â”œâ”€â”€ test_api_only.py            # FREE API connection test
â”‚   â”œâ”€â”€ README.md                    # FAL AI dual-model documentation
â”‚   â”œâ”€â”€ COST_CONSCIOUS_TESTING.md   # Cost-conscious testing guide
â”‚   â”œâ”€â”€ requirements.txt             # FAL AI dependencies
â”‚   â”œâ”€â”€ .env                         # FAL AI configuration
â”‚   â”œâ”€â”€ output/                      # FAL AI generated videos
â”‚   â””â”€â”€ test_output/                 # Test-generated videos
â”œâ”€â”€ fal_avatar_generation/           # FAL AI triple-mode avatar implementation
â”‚   â”œâ”€â”€ fal_avatar_generator.py      # FAL AI avatar generator class (triple-mode)
â”‚   â”œâ”€â”€ demo.py                      # Cost-conscious interactive demo with mode selection
â”‚   â”œâ”€â”€ test_official_example.py    # Test using exact FAL AI documentation examples
â”‚   â”œâ”€â”€ test_setup.py               # FREE environment and API validation
â”‚   â”œâ”€â”€ test_generation.py          # PAID avatar generation tests (voice/audio/multi flags)
â”‚   â”œâ”€â”€ README.md                    # FAL AI avatar documentation
â”‚   â”œâ”€â”€ requirements.txt             # FAL AI dependencies
â”‚   â”œâ”€â”€ .env                         # FAL AI configuration
â”‚   â”œâ”€â”€ output/                      # Generated avatar videos
â”‚   â””â”€â”€ test_output/                 # Test-generated avatar videos
â””â”€â”€ fal_text_to_image/               # FAL AI quad-model text-to-image implementation
    â”œâ”€â”€ fal_text_to_image_generator.py # FAL AI text-to-image generator class
    â”œâ”€â”€ demo.py                      # Cost-conscious interactive demo
    â”œâ”€â”€ test_setup.py               # FREE environment and API validation
    â”œâ”€â”€ test_generation.py          # PAID image generation tests (includes --dragon)
    â”œâ”€â”€ README.md                    # FAL AI text-to-image documentation
    â”œâ”€â”€ requirements.txt             # FAL AI dependencies
    â”œâ”€â”€ .env                         # FAL AI configuration
    â”œâ”€â”€ output/                      # Generated images
    â””â”€â”€ test_output/                 # Test-generated images
```

## Configuration Requirements

### Google Veo Setup
- **Quick Setup**: Run `python fix_permissions.py` (fixes 90% of issues automatically)
- Google Cloud Project ID (configured in [veo3_video_generation/.env](mdc:veo3_video_generation/.env))
- Google Cloud Storage bucket for output
- Vertex AI API enabled (automated by fix script)
- gcloud CLI authentication

### FAL AI Setup (Simpler)
- FAL AI API key in respective `.env` files:
  - [fal_video_generation/.env](mdc:fal_video_generation/.env)
  - [fal_avatar_generation/.env](mdc:fal_avatar_generation/.env)  
  - [fal_text_to_image/.env](mdc:fal_text_to_image/.env)
- Python dependencies: fal-client, requests, python-dotenv
- Single API key works for all FAL AI models (video, avatar, image)

## Model Selection Guidelines

### Choose MiniMax Hailuo-02 when:
- You need reliable 768p video generation
- You want AI-powered prompt optimization
- You prefer the established model with proven results

### Choose Kling Video 2.1 when:
- You need high-quality video output
- You want fine control with CFG scale parameters
- You need negative prompt capabilities for better quality control

### Choose Google Veo when:
- You need 1080p resolution
- You want longer videos
- You already use Google Cloud infrastructure

### Choose FAL AI Avatar Generation when:
- You need talking avatars with lip-sync
- You want text-to-speech conversion with 20 voice options
- You need custom audio file lip-sync animation
- You want multi-person conversation videos
- You need natural facial expressions and movements

## Usage Recommendations

### Video Generation
- **Testing Setup**: Use `python test_api_only.py` for FREE API validation
- **Prototyping**: Start with FAL AI single model testing (`--hailuo` or `--kling`) to avoid unnecessary costs
- **Production**: Use FAL AI for API-based deployments, Google Veo for high-resolution needs
- **Comparison**: Use cost-conscious comparison tools - remember comparison tests generate 2 videos (~$0.04-0.10)

### Avatar Generation
- **Testing Setup**: Use `python test_setup.py` for FREE environment validation
- **Official Testing**: Use `python test_official_example.py` for exact FAL AI documentation examples
- **Prototyping**: Start with single mode testing (`python test_generation.py --voice Bill`) to avoid unnecessary costs
- **Voice Testing**: Use `python test_generation.py --voice [VoiceName]` for specific voice testing (~$0.03-0.05)
- **Audio Testing**: Use `python test_generation.py --audio` for custom audio file testing (~$0.03-0.05)
- **Conversation Testing**: Use `python test_generation.py --multi` for multi-person conversation testing (~$0.03-0.05)
- **Production**: Use official examples as defaults, customize parameters as needed

### Text-to-Image Generation
- **Testing Setup**: Use `python test_setup.py` for FREE environment validation
- **Prototyping**: Start with single model testing (`python test_generation.py --flux-schnell`) to avoid unnecessary costs
- **Dragon Generation**: Use `python test_generation.py --dragon` for dragon image testing (~$0.015)
- **Production**: Use batch generation for efficiency (`python test_generation.py --batch 1,3`)
- **Comparison**: Use comparison tools carefully - remember comparison tests generate 4 images (~$0.060)

## âš ï¸ CRITICAL: Cost Protection Rules
**See [cost-protection.mdc](mdc:.cursor/rules/cost-protection.mdc) for complete cost protection guidelines**

### Video Generation
- **NEVER run video generation tests without explicit user confirmation**
- **Always start with FREE tests** (`test_api_only.py`) to validate setup
- **Use model-specific flags** (`--hailuo`, `--kling`) to test individual models
- **Avoid comparison tests** during development unless specifically needed
- **Monitor costs** - each video generation costs ~$0.02-0.05

### Avatar Generation
- **NEVER run avatar generation tests without explicit user confirmation**
- **Always start with FREE tests** (`test_setup.py`) to validate setup
- **Use official examples** (`test_official_example.py`) for documentation compliance
- **Use mode-specific flags** (`--voice`, `--audio`, `--multi`) to test individual modes
- **Avoid comparison tests** during development unless specifically needed
- **Monitor costs** - each avatar generation costs ~$0.02-0.05

### Text-to-Image Generation
- **NEVER run image generation tests without explicit user confirmation**
- **Always start with FREE tests** (`test_setup.py`) to validate setup
- **Use model-specific flags** (`--imagen4`, `--seedream`, `--flux-schnell`, `--flux-dev`) to test individual models
- **Use dragon generation** (`--dragon`) for testing specific scenarios
- **Avoid comparison tests** (`--compare`) during development unless specifically needed
- **Monitor costs** - each image generation costs ~$0.015









