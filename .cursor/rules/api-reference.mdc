---
description:
globs:
alwaysApply: false
---
# API Reference Guide

This project provides comprehensive AI content generation APIs: Google Veo (complex, high-quality video), FAL AI Video Generation (dual-model, production-ready), FAL AI Avatar Generation (triple-mode, lip-sync), and FAL AI Text-to-Image Generation (quad-model).

## Google Veo API Functions
All functions are located in [packages/providers/google/veo/veo_video_generation.py](mdc:packages/providers/google/veo/veo_video_generation.py).

### Text-to-Video Generation
```python
generate_video_from_text(
    project_id: str,
    prompt: str,
    output_bucket_path: str,
    model_id: str = "veo-2.0-generate-001",
    location: str = "us-central1"
) -> str | None
```
**Purpose**: Generate video from text description  
**Returns**: GCS URI of generated video or None on error

### Image-to-Video Generation
```python
generate_video_from_image(
    project_id: str,
    image_path: str,  # GCS URI or local path
    output_bucket_path: str,
    prompt: str = None,  # Optional text guidance
    model_id: str = "veo-2.0-generate-001",
    location: str = "us-central1"
) -> str | None
```
**Purpose**: Generate video from image with optional text guidance  
**Returns**: GCS URI of generated video or None on error

### Local Image Upload and Generation
```python
generate_video_from_local_image(
    project_id: str,
    image_filename: str,  # Local file path
    output_bucket_path: str,
    prompt: str = None,
    model_id: str = "veo-2.0-generate-001",
    location: str = "us-central1"
) -> str | None
```
**Purpose**: Upload local image to GCS and generate video  
**Returns**: GCS URI of generated video or None on error

### Veo 3.0 Preview Generation
```python
generate_video_with_veo3_preview(
    project_id: str,
    prompt: str,
    output_bucket_path: str,
    location: str = "us-central1"
) -> str | None
```
**Purpose**: Generate video using Veo 3.0 preview model  
**Returns**: GCS URI of generated video or None on error

### File Download Utility
```python
download_gcs_file(
    gcs_uri: str,
    local_folder_path: str,
    project_id: str
) -> str | None
```
**Purpose**: Download generated video from GCS to local folder  
**Returns**: Local file path or None on error

## FAL AI Video Generation API Class
Located in [packages/providers/fal/video/fal_video_generator.py](mdc:packages/providers/fal/video/fal_video_generator.py).

### FALImageToVideoGenerator Class
```python
from fal_image_to_video_generator import FALImageToVideoGenerator

# Initialize with API key (from .env or parameter)
generator = FALImageToVideoGenerator(api_key=None)  # Uses FAL_KEY from .env
```

### Universal Methods (Model Selection)

#### Generate Video from Image URL
```python
generator.generate_video_from_image(
    prompt: str,                    # Text description
    image_url: str,                 # Online image URL
    duration: str = "6",            # "5", "6", or "10" seconds
    model: str = "hailuo",          # "hailuo" or "kling"
    output_folder: str = "output",  # Local download folder
    use_async: bool = False         # Async processing mode
) -> Optional[Dict[str, Any]]
```
**Purpose**: Generate video from online image with model selection  
**Returns**: Dictionary with video URL, metadata, and local path

#### Generate Video from Local Image
```python
generator.generate_video_from_local_image(
    prompt: str,                    # Text description
    image_path: str,                # Local image file path
    duration: str = "6",            # "5", "6", or "10" seconds
    model: str = "hailuo",          # "hailuo" or "kling"
    output_folder: str = "output",  # Local download folder
    use_async: bool = False         # Async processing mode
) -> Optional[Dict[str, Any]]
```
**Purpose**: Upload local image and generate video with model selection  
**Returns**: Dictionary with video URL, metadata, and local path

### Model-Specific Methods

#### MiniMax Hailuo-02 Optimized Generation
```python
generator.generate_video_with_hailuo(
    prompt: str,                    # Text description
    image_url: str,                 # Online image URL
    duration: str = "6",            # "6" or "10" seconds
    prompt_optimizer: bool = True,  # Use AI prompt optimization
    output_folder: str = "output",  # Local download folder
    use_async: bool = False         # Async processing mode
) -> Optional[Dict[str, Any]]
```
**Purpose**: Generate video using MiniMax Hailuo-02 with optimized parameters  
**Returns**: Dictionary with video URL, metadata, and local path

#### Kling Video 2.1 Optimized Generation
```python
generator.generate_video_with_kling(
    prompt: str,                           # Text description
    image_url: str,                        # Online image URL
    duration: str = "5",                   # "5" or "10" seconds
    negative_prompt: str = "blur, distort, and low quality",  # Quality control
    cfg_scale: float = 0.5,                # Generation guidance (0.1-2.0)
    output_folder: str = "output",         # Local download folder
    use_async: bool = False                # Async processing mode
) -> Optional[Dict[str, Any]]
```
**Purpose**: Generate video using Kling Video 2.1 with optimized parameters  
**Returns**: Dictionary with video URL, metadata, and local path

### Utility Methods

#### Upload Local Image
```python
generator.upload_local_image(
    image_path: str                 # Path to local image file
) -> Optional[str]
```
**Purpose**: Upload local image to FAL AI and get URL  
**Returns**: Image URL or None if failed

#### Download Video
```python
generator.download_video(
    video_url: str,                 # FAL AI video URL
    output_folder: str,             # Local folder for download
    filename: str                   # Output filename
) -> Optional[str]
```
**Purpose**: Download generated video to local folder  
**Returns**: Local file path or None if failed

## FAL AI Avatar Generation API Class
Located in [packages/providers/fal/avatar/fal_avatar_generator.py](mdc:packages/providers/fal/avatar/fal_avatar_generator.py).

### FALAvatarGenerator Class
```python
from fal_avatar_generator import FALAvatarGenerator, VOICE_OPTIONS

# Initialize with API key (from .env or parameter)
generator = FALAvatarGenerator(api_key=None)  # Uses FAL_KEY from .env
```

### Universal Methods (Mode Selection)

#### Text-to-Speech Avatar Generation
```python
generator.generate_avatar_video(
    image_url: str,                 # Image URL or local file path
    text_input: str,                # Text that avatar will speak
    voice: VoiceType = "Bill",      # Voice option (20 available, Bill is official example)
    prompt: str = "An elderly man with a white beard and headphones records audio with a microphone. He appears engaged and expressive, suggesting a podcast or voiceover.",  # Official example prompt
    num_frames: int = 136,          # Frame count (81-129, default: 136 - official example)
    seed: Optional[int] = 42,       # Random seed (default: 42 - official example)
    turbo: bool = True,             # Turbo mode for faster generation
    output_path: Optional[str] = None  # Local save path
) -> Dict[str, Any]
```
**Purpose**: Generate talking avatar video from text with natural speech conversion  
**Returns**: Dictionary with video URL, generation metadata, and parameters  
**Voice Options**: 20 voices available (see VOICE_OPTIONS list)

#### Audio-to-Avatar Generation
```python
generator.generate_avatar_from_audio(
    image_url: str,                 # Image URL or local file path
    audio_url: str,                 # Audio URL or local file path
    prompt: str = "A person speaking naturally with clear lip-sync and natural expressions.",
    num_frames: int = 145,          # Frame count (81-129, default: 145)
    seed: Optional[int] = None,     # Random seed for reproducibility
    turbo: bool = True,             # Turbo mode for faster generation
    output_path: Optional[str] = None  # Local save path
) -> Dict[str, Any]
```
**Purpose**: Generate talking avatar video from custom audio file with lip-sync  
**Returns**: Dictionary with video URL, generation metadata, and parameters  
**Audio Support**: MP3, WAV, and other common audio formats

#### Multi-Audio Conversation Generation
```python
generator.generate_multi_avatar_conversation(
    image_url: str,                 # Image URL or local file path
    first_audio_url: str,           # First person's audio URL or local file path
    second_audio_url: str,          # Second person's audio URL or local file path
    prompt: str = "Two people engaged in a natural conversation, speaking in sequence with clear lip-sync and natural expressions.",
    num_frames: int = 181,          # Frame count (81-129, default: 181)
    seed: Optional[int] = None,     # Random seed for reproducibility
    turbo: bool = True,             # Turbo mode for faster generation
    output_path: Optional[str] = None  # Local save path
) -> Dict[str, Any]
```
**Purpose**: Generate conversation video with two people speaking sequentially  
**Returns**: Dictionary with video URL, generation metadata, and parameters  
**Audio Support**: Multiple audio files for conversation flow

#### Official FAL AI Example Generation
```python
generator.generate_official_example(
    output_path: Optional[str] = None  # Local save path
) -> Dict[str, Any]
```
**Purpose**: Generate avatar video using exact FAL AI documentation example  
**Returns**: Dictionary with video URL, generation metadata, and parameters  
**Use Case**: Documentation compliance testing and reference implementation

### Utility Methods

#### Get Available Voices
```python
generator.get_available_voices() -> list
```
**Purpose**: Get list of all 20 available voice options  
**Returns**: List of voice names

#### Test API Connection
```python
generator.test_connection() -> bool
```
**Purpose**: Test API connectivity without generating content (FREE)  
**Returns**: True if connection successful, False otherwise

#### Download Video
```python
generator._download_video(
    video_url: str,                 # FAL AI video URL
    output_path: str                # Local file path
) -> None
```
**Purpose**: Download generated avatar video to local file  
**Returns**: None (internal method)

## FAL AI Text-to-Image Generation API Class
Located in [fal_text_to_image/fal_text_to_image_generator.py](mdc:fal_text_to_image/fal_text_to_image_generator.py).

### FALTextToImageGenerator Class
```python
from fal_text_to_image_generator import FALTextToImageGenerator

# Initialize with API key (from .env or parameter)
generator = FALTextToImageGenerator(api_key=None)  # Uses FAL_KEY from .env
```

### Universal Methods (Model Selection)

#### Generate Single Image
```python
generator.generate_image(
    prompt: str,                    # Text description of desired image
    model: str = "imagen4",         # "imagen4", "seedream", "flux_schnell", "flux_dev"
    negative_prompt: str = "",      # What to avoid in the image
    output_folder: str = "output",  # Local download folder
    auto_confirm: bool = False      # Skip cost confirmation prompt
) -> Optional[Dict[str, Any]]
```
**Purpose**: Generate single image with specified model  
**Returns**: Dictionary with image URL, metadata, and local path

#### Batch Generate with Multiple Models
```python
generator.batch_generate(
    prompt: str,                    # Text description of desired image
    models: List[str],              # List of models to use
    negative_prompt: str = "",      # What to avoid in the image
    output_folder: str = "output",  # Local download folder
    auto_confirm: bool = False,     # Skip cost confirmation prompt
    download_images: bool = True    # Auto-download generated images
) -> Dict[str, Any]
```
**Purpose**: Generate images with multiple models for comparison  
**Returns**: Dictionary with results summary and individual model results

### Model-Specific Methods

#### Imagen4 Optimized Generation
```python
generator.generate_image_with_imagen4(
    prompt: str,                    # Text description
    negative_prompt: str = "",      # Quality control
    num_inference_steps: int = 50,  # Generation steps (higher = better quality)
    output_folder: str = "output"   # Local download folder
) -> Optional[Dict[str, Any]]
```
**Purpose**: Generate image using Google's Imagen4 with optimized parameters  
**Returns**: Dictionary with image URL, metadata, and local path

#### FLUX Schnell Fast Generation
```python
generator.generate_image_with_flux_schnell(
    prompt: str,                    # Text description
    num_inference_steps: int = 4,   # Generation steps (lower = faster)
    output_folder: str = "output"   # Local download folder
) -> Optional[Dict[str, Any]]
```
**Purpose**: Generate image using FLUX Schnell for ultra-fast results  
**Returns**: Dictionary with image URL, metadata, and local path

## FAL AI Image-to-Image Generation API Class
Located in [fal_image_to_image/fal_image_to_image/](mdc:fal_image_to_image/fal_image_to_image/) directory with professional package structure.

### FALImageToImageGenerator Class
```python
from fal_image_to_image import FALImageToImageGenerator

# Initialize with API key (from .env or parameter)
generator = FALImageToImageGenerator(api_key=None)  # Uses FAL_KEY from .env
```

### Universal Methods (Enhancement Selection)

#### Enhance Single Image
```python
generator.enhance_image(
    input_image: str,               # Input image path or URL
    prompt: str,                    # Enhancement description
    enhancement_type: str = "style_transfer",  # "style_transfer", "upscale", "artistic"
    output_folder: str = "output",  # Local download folder
    auto_confirm: bool = False      # Skip cost confirmation prompt
) -> Optional[Dict[str, Any]]
```
**Purpose**: Enhance single image with specified enhancement type  
**Returns**: Dictionary with enhanced image URL, metadata, and local path

#### Batch Enhancement Processing
```python
generator.batch_enhance(
    input_images: List[str],        # List of input image paths or URLs
    prompt: str,                    # Enhancement description
    enhancement_type: str = "upscale",  # Enhancement mode
    output_folder: str = "output",  # Local download folder
    auto_confirm: bool = False,     # Skip cost confirmation prompt
    download_images: bool = True    # Auto-download enhanced images
) -> Dict[str, Any]
```
**Purpose**: Enhance multiple images with batch processing  
**Returns**: Dictionary with results summary and individual enhancement results

### Enhancement-Specific Methods

#### Style Transfer Enhancement
```python
generator.enhance_with_style_transfer(
    input_image: str,               # Input image path or URL
    style_prompt: str,              # Style description
    strength: float = 0.8,          # Enhancement strength (0.1-1.0)
    output_folder: str = "output"   # Local download folder
) -> Optional[Dict[str, Any]]
```
**Purpose**: Apply style transfer to input image with FLUX models  
**Returns**: Dictionary with enhanced image URL, metadata, and local path

#### Image Upscaling Enhancement
```python
generator.enhance_with_upscaling(
    input_image: str,               # Input image path or URL
    scale_factor: int = 2,          # Upscaling factor (2x, 4x)
    quality_mode: str = "high",     # "high", "balanced", "fast"
    output_folder: str = "output"   # Local download folder
) -> Optional[Dict[str, Any]]
```
**Purpose**: Upscale image while maintaining quality with AI enhancement  
**Returns**: Dictionary with enhanced image URL, metadata, and local path

### Utility Methods

#### Get Enhancement Modes
```python
generator.get_enhancement_modes() -> List[str]
```
**Purpose**: Get list of all available enhancement types  
**Returns**: List of enhancement mode names

#### Compare Enhancement Results
```python
generator.compare_enhancements(
    input_image: str,               # Input image path or URL
    enhancement_types: List[str],   # List of enhancement types to compare
    prompt: str,                    # Enhancement description
    output_folder: str = "output"   # Local download folder
) -> Dict[str, Any]
```
**Purpose**: Compare different enhancement modes on the same image  
**Returns**: Dictionary with comparison results and individual enhancements

## Configuration Objects

### Google Veo Configuration
```python
from google.genai.types import GenerateVideosConfig

config = GenerateVideosConfig(
    aspect_ratio="16:9",  # "4:3", "1:1", etc.
    output_gcs_uri="gs://bucket/path/",
    duration_seconds=5,   # Optional
    fps=24               # Optional
)
```

### FAL AI Response Structures

#### Video Generation Response
```python
# MiniMax Hailuo-02 Response
{
    'video': {
        'url': 'https://v3.fal.media/files/...',
        'file_name': 'output.mp4',
        'file_size': 2816883
    },
    'duration': '6',
    'width': 768,
    'height': 768,
    'model': 'hailuo',
    'local_path': 'output/video.mp4'  # If downloaded
}

# Kling Video 2.1 Response
{
    'video': {
        'url': 'https://v3.fal.media/files/...',
        'file_name': 'output.mp4',
        'file_size': 3445621
    },
    'duration': '5',
    'model': 'kling',
    'local_path': 'output/video.mp4'  # If downloaded
}
```

#### Avatar Generation Response
```python
# Text-to-Speech Avatar Response
{
    'video': {
        'url': 'https://v3.fal.media/files/...',
        'file_name': 'output.mp4',
        'file_size': 2816883
    },
    'generation_time': 15.42,
    'parameters': {
        'image_url': 'https://v3.fal.media/files/panda/HuM21CXMf0q7OO2zbvwhV_c4533aada79a495b90e50e32dc9b83a8.png',
        'text_input': 'Spend more time with people who make you feel alive, and less with things that drain your soul.',
        'voice': 'Bill',
        'prompt': 'An elderly man with a white beard and headphones records audio with a microphone. He appears engaged and expressive, suggesting a podcast or voiceover.',
        'num_frames': 136,
        'seed': 42,
        'turbo': True
    },
    'local_path': 'output/avatar_video.mp4'  # If downloaded
}

# Audio-to-Avatar Response
{
    'video': {
        'url': 'https://v3.fal.media/files/...',
        'file_name': 'output.mp4',
        'file_size': 3124789
    },
    'generation_time': 18.67,
    'parameters': {
        'image_url': 'path/to/image.jpg',
        'audio_url': 'path/to/audio.mp3',
        'prompt': 'A person speaking naturally with clear lip-sync and natural expressions.',
        'num_frames': 145,
        'turbo': True
    },
    'local_path': 'output/avatar_video.mp4'  # If downloaded
}

# Multi-Audio Conversation Response
{
    'video': {
        'url': 'https://v3.fal.media/files/...',
        'file_name': 'output.mp4',
        'file_size': 4567890
    },
    'generation_time': 22.34,
    'parameters': {
        'image_url': 'path/to/image.jpg',
        'first_audio_url': 'path/to/person1_audio.mp3',
        'second_audio_url': 'path/to/person2_audio.mp3',
        'prompt': 'Two people engaged in a natural conversation, speaking in sequence with clear lip-sync and natural expressions.',
        'num_frames': 181,
        'turbo': True
    },
    'local_path': 'output/conversation_video.mp4'  # If downloaded
}
```

#### Text-to-Image Response
```python
# Single Image Generation Response
{
    'image': {
        'url': 'https://v3.fal.media/files/...',
        'file_name': 'output.png',
        'file_size': 1024768
    },
    'model': 'imagen4',
    'local_path': 'output/image.png',
    'generation_time': 6.42,
    'cost_estimate': 0.015
}

# Batch Generation Response
{
    'results': [
        {
            'model': 'imagen4',
            'success': True,
            'image_url': 'https://v3.fal.media/files/...',
            'local_path': 'output/imagen4_image.png',
            'generation_time': 6.42
        },
        {
            'model': 'flux_schnell',
            'success': True,
            'image_url': 'https://v3.fal.media/files/...',
            'local_path': 'output/flux_schnell_image.png',
            'generation_time': 1.23
        }
    ],
    'summary': {
        'total_images': 2,
        'successful': 2,
        'failed': 0,
        'total_time': 7.65,
        'total_cost': 0.030,
        'success_rate': 100.0
    }
}
```

## Voice Options (Avatar Generation)

### Available Voices (20 Total)
```python
# Male Voices (12)
MALE_VOICES = [
    "Roger", "Charlie", "George", "Callum", "River", 
    "Liam", "Will", "Eric", "Chris", "Brian", "Daniel", "Bill"
]

# Female Voices (8)
FEMALE_VOICES = [
    "Aria", "Sarah", "Laura", "Charlotte", 
    "Alice", "Matilda", "Jessica", "Lily"
]

# Official Example Voice (recommended default)
OFFICIAL_VOICE = "Bill"
```

### Voice Selection Usage
```python
from fal_avatar_generator import FALAvatarGenerator, VOICE_OPTIONS

generator = FALAvatarGenerator()

# Use official example voice (recommended)
result = generator.generate_avatar_video(
    image_url="path/to/image.jpg",
    text_input="Your text here",
    voice="Bill"  # Official example default
)

# Use any available voice
for voice in VOICE_OPTIONS:
    print(f"Available voice: {voice}")
```

## Error Handling and Status Codes

### Common Error Types
```python
# API Authentication Errors
{
    'error': 'authentication_failed',
    'message': 'Invalid API key or insufficient permissions',
    'code': 401
}

# Generation Errors
{
    'error': 'generation_failed',
    'message': 'Failed to generate content with specified parameters',
    'code': 500,
    'details': 'Model-specific error information'
}

# Parameter Validation Errors
{
    'error': 'validation_error',
    'message': 'Invalid parameter values provided',
    'code': 400,
    'invalid_params': ['duration', 'num_frames']
}
```

### Retry Mechanisms
All API classes include automatic retry logic:
- Network timeouts: 3 retries with exponential backoff
- Rate limiting: Automatic retry with proper delays
- Server errors: Configurable retry attempts

## Best Practices

### API Usage Guidelines
1. **Always validate API keys** before making requests
2. **Use appropriate timeouts** for generation requests (2-5 minutes)
3. **Implement proper error handling** for all API calls
4. **Cache results** to avoid regenerating identical content
5. **Monitor costs** carefully when using paid generation methods

### Performance Optimization
1. **Batch operations** when possible to reduce API overhead
2. **Use model-specific methods** for optimized parameters
3. **Download content locally** to avoid repeated API calls
4. **Use appropriate image sizes** to balance quality and processing time

### Cost Management
1. **Test with FREE methods first** (`test_setup.py`, `test_api_only.py`)
2. **Use single model/mode flags** during development
3. **Avoid comparison operations** unless specifically needed
4. **Monitor generation costs** and set appropriate limits
5. **Use official examples** for avatar generation to ensure compliance
