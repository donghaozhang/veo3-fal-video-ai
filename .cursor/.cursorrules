# Cursor AI Assistant Rules for AI Content Generation Platform

## Project Overview
This is a comprehensive AI content generation platform with multiple specialized implementations and a unified AI Content Pipeline as the flagship feature.

### 🚀 **FLAGSHIP: AI Content Pipeline (ai_content_pipeline/)**
- **Unified YAML-based pipeline** for multi-step content generation
- **Parallel execution support** with 2-3x speedup using thread-based processing
- **All model integration**: FAL AI, ElevenLabs TTS, Google services
- **Feature flag**: `PIPELINE_PARALLEL_ENABLED=true` for parallel execution
- **Command**: `python -m ai_content_pipeline run-chain --config config.yaml`

### Individual Service Implementations:
- **Google Veo** (veo3_video_generation/) - High-resolution, enterprise-grade video generation
- **FAL AI Video** (fal_video_generation/) - Simple API-based generation with dual models
- **FAL AI Text-to-Video** (fal_text_to_video/) - Unified text-to-video with dual model support
- **FAL AI Video-to-Video** (fal_video_to_video/) - Audio generation and video upscaling
- **FAL AI Avatar** (fal_avatar_generation/) - Talking avatar generation
- **FAL AI Text-to-Image** (fal_text_to_image/) - Multi-model image generation
- **FAL AI Image-to-Image** (fal_image_to_image/) - AI-powered image modification
- **✨ Text-to-Speech** (text_to_speech/) - Professional voice synthesis with ElevenLabs + OpenRouter
- **🔧 Video Tools** (video_tools/) - Comprehensive video processing with enhanced CLI

## **FLAGSHIP: AI Content Pipeline Architecture** (PARALLEL EXECUTION READY)

### Unified Content Creation System with Parallel Processing
The ai_content_pipeline provides a unified interface for chaining multiple AI operations with **parallel execution support**:
**Text → Image → Video → Audio Enhancement → Video Upscaling** (Sequential or Parallel)

```
ai_content_pipeline/
├── ai_content_pipeline/           # Main package
│   ├── config/                   # Configuration management
│   ├── models/                   # Model implementations
│   │   ├── text_to_speech.py     # ElevenLabs TTS integration
│   │   ├── text_to_image.py      # FAL AI image generation
│   │   ├── image_to_image.py     # FAL AI image modification
│   │   └── base.py               # Base model interface
│   ├── pipeline/                 # Pipeline management
│   │   ├── manager.py            # Main pipeline manager
│   │   ├── chain.py              # Chain configuration classes
│   │   ├── executor.py           # Chain execution engine
│   │   └── parallel_extension.py # **NEW: Parallel execution module**
│   ├── utils/                    # File management and validation
│   ├── docs/                     # **NEW: Complete documentation**
│   ├── examples/                 # **NEW: Example scripts and POCs**
│   └── input/                    # YAML configuration files
```

### **NEW: Parallel Execution Features**
- **StepType.PARALLEL_GROUP**: Execute multiple steps concurrently
- **Thread-based processing**: 2-3x speedup for parallel operations
- **Merge strategies**: collect_all, first_success, best_quality
- **Feature flag**: `PIPELINE_PARALLEL_ENABLED=true`
- **Backward compatible**: Zero breaking changes to existing workflows

### Pipeline Usage Patterns
```python
# ✅ Correct - YAML-based pipeline execution
# Sequential execution
python -m ai_content_pipeline run-chain --config input/tts_simple_test.yaml

# Parallel execution (2-3x speedup)
PIPELINE_PARALLEL_ENABLED=true python -m ai_content_pipeline run-chain --config input/tts_parallel_test.yaml

# Debug mode
python -m ai_content_pipeline run-chain --config config.yaml --debug
```

```yaml
# ✅ YAML Configuration Example - Parallel TTS Generation
pipeline_name: "parallel_tts_example"
description: "Generate multiple TTS files in parallel"
output_directory: "ai_content_pipeline/output/"

steps:
  - step_type: "parallel_group"
    parallel_config:
      merge_strategy: "collect_all"
    steps:
      - step_type: "text_to_speech"
        config:
          text: "Hello from voice 1"
          voice: "Adam"
        output_filename: "voice1.mp3"
      - step_type: "text_to_speech"
        config:
          text: "Hello from voice 2"
          voice: "Rachel"
        output_filename: "voice2.mp3"
```

## FAL AI Text-to-Video Architecture (RECENTLY ENHANCED)

### Unified Text-to-Video Generation
The fal_text_to_video module provides direct text-to-video generation with dual model support:

```
fal_text_to_video/
├── fal_text_to_video/            # Main package directory
│   ├── __init__.py               # Package initialization
│   ├── generator.py              # Unified dual-model generator
│   ├── models/                   # Model implementations
│   │   ├── hailuo_pro.py         # MiniMax Hailuo-02 Pro model
│   │   └── veo3.py               # Google Veo 3 model
│   ├── config/                   # Configuration and constants
│   └── utils/                    # Utilities and validation
├── examples/                     # Usage examples and demos
├── tests/                        # Test suite
├── docs/                         # Documentation
├── README.md                     # Text-to-video documentation
└── requirements.txt              # Text-to-video dependencies
```

### Model Support
- **MiniMax Hailuo-02 Pro** (Default): $0.08/video, 1080p, 6s duration
- **Google Veo 3** (Premium): $2.50-$6.00/video, 720p, 5-8s duration, audio support

### Import Patterns
```python
# ✅ Correct - Text-to-video generation
from fal_text_to_video import FALTextToVideoGenerator, TextToVideoModel

generator = FALTextToVideoGenerator(verbose=True)
result = generator.generate_video(
    prompt="A majestic eagle soaring over mountains",
    model=TextToVideoModel.MINIMAX_HAILUO  # Cost-effective option
)
```

## FAL AI Video-to-Video Architecture (RECENTLY ENHANCED)

### Dual-Model Video Processing
The fal_video_to_video module provides AI-powered video enhancement with dual model support:

```
fal_video_to_video/
├── fal_video_to_video/            # Main package directory
│   ├── __init__.py                # Package initialization
│   ├── __main__.py                # CLI entry point
│   ├── generator.py               # Core video-to-video logic
│   ├── models/                    # Model implementations
│   │   ├── thinksound.py          # ThinksSound AI audio generation
│   │   └── topaz.py               # Topaz Video Upscale model
│   ├── config/                    # Configuration management
│   └── utils/                     # Utility functions
├── examples/                      # Usage examples and demos
├── tests/                         # Test suite
├── input/                         # Input videos for testing
├── output/                        # Generated videos output
├── setup.py                       # Package installation
├── requirements.txt               # Video-to-video dependencies
└── README.md                      # Video-to-video documentation
```

### Dual-Model Features
- **ThinksSound**: AI-powered audio generation with custom prompts (~$0.05-0.10/video)
- **Topaz Video Upscale**: Professional video enhancement up to 4x resolution (~$0.50-2.50/video)
- **Frame Interpolation**: Target FPS control for smooth video playback
- **Unified CLI**: Single command structure for both models
- **Batch Processing**: Process multiple videos with JSON configuration

### CLI Usage Patterns
```bash
# Add AI-generated audio to video
python -m fal_video_to_video add-audio -i input/video.mp4 -p "add dramatic music"

# Upscale video with 2x factor
python -m fal_video_to_video upscale -i input/video.mp4 --upscale-factor 2

# Upscale with frame interpolation to 60 FPS
python -m fal_video_to_video upscale -i input/video.mp4 --upscale-factor 2 --target-fps 60

# Batch processing
python -m fal_video_to_video batch -f batch.json
```

## Text-to-Speech Package Architecture (RECENTLY REFACTORED)

### Package Structure
The text_to_speech package has been refactored from monolithic files to a professional modular structure:

```
text_to_speech/
├── models/          # Data models and enums
│   ├── common.py    # Shared models (VoiceSettings, AudioFormat, etc.)
│   └── pipeline.py  # Pipeline-specific models
├── tts/             # Core TTS functionality
│   ├── controller.py      # Main TTS controller
│   ├── voice_manager.py   # Voice selection and management
│   └── audio_processor.py # Audio format handling
├── pipeline/        # OpenRouter AI integration
│   └── core.py      # Complete pipeline orchestration
├── utils/           # Utility functions
│   ├── file_manager.py    # File operations
│   ├── api_helpers.py     # API utilities
│   └── validators.py      # Input validation
├── config/          # Configuration management
│   ├── voices.py    # Voice presets and configurations
│   ├── models.py    # Model settings and recommendations
│   └── defaults.py  # Default values and settings
├── examples/        # Usage examples
│   └── basic_usage.py     # Basic TTS examples
└── cli/             # Command line tools
    ├── interactive.py     # Interactive pipeline
    └── quick_start.py     # Quick demo runner
```

### Import Patterns
**Always use the new modular imports:**
```python
# ✅ Correct - Main package interface
from text_to_speech import ElevenLabsTTSController, ElevenLabsModel, VoiceSettings

# ✅ Correct - Direct module imports
from text_to_speech.tts.controller import ElevenLabsTTSController
from text_to_speech.models.common import ElevenLabsModel, VoiceSettings
from text_to_speech.pipeline.core import OpenRouterTTSPipeline

# ❌ Avoid - Old monolithic imports (removed)
from elevenlabs_tts_controller import ElevenLabsTTSController  # FILE REMOVED
from openrouter_tts_pipeline import OpenRouterTTSPipeline      # FILE REMOVED
```

### Migration Notes
- Old monolithic files have been removed: elevenlabs_tts_controller.py, openrouter_tts_pipeline.py, elevenlabs_dialogue_controller.py
- All functionality preserved in new modular structure
- Migration guide available: text_to_speech/MIGRATION_GUIDE.md
- Backward compatibility maintained through main package interface

## Video Tools Enhanced CLI Architecture (RECENTLY IMPLEMENTED)

### Enhanced Commands with Parameter Support
The video_tools package now supports enhanced CLI parameter mode for specific commands:

```bash
# Enhanced generate-subtitles with -i, -o, -f parameters
python3 video_audio_utils.py generate-subtitles -i video.mp4 -o subtitle.srt
python3 video_audio_utils.py generate-subtitles -i input/ -o output/ -f vtt

# Enhanced describe-videos with parameters
python3 video_audio_utils.py describe-videos -i video.mp4 -o output.json -f describe-video

# Enhanced transcribe-videos with parameters  
python3 video_audio_utils.py transcribe-videos -i video.mp4 -o output.json -f json
```

### Parameter Support Pattern
Commands support enhanced mode when `-i`, `-o`, or `-f` parameters are provided:
- `-i`: Input file or directory path
- `-o`: Output file or directory path  
- `-f`: Format specification (varies by command)

### Implementation Pattern
Enhanced commands follow this architecture:
1. `cmd_[command]_enhanced()` wrapper function in video_audio_utils.py
2. `cmd_[command]_with_params()` implementation in respective modules
3. Automatic detection and routing based on parameter presence
4. Backward compatibility with traditional mode (no parameters)

## Development Guidelines

### AI Content Pipeline
1. **Chain Design**: Use YAML/JSON for complex workflows
2. **Model Selection**: Prefer "auto" selection with criteria and budget constraints
3. **Cost Estimation**: Always provide transparent cost estimates
4. **File Management**: Use temporary directories and cleanup
5. **Validation**: Validate chain compatibility before execution

### FAL AI Text-to-Video
1. **Model Selection**: Use MiniMax Hailuo-02 Pro for cost-effective generation, Google Veo 3 for premium quality
2. **Cost Consciousness**: Always warn about costs ($0.08-$6.00 per video)
3. **Setup Testing**: Use `test_setup.py` for FREE validation before paid operations
4. **Prompt Optimization**: Enable prompt optimization for better results
5. **Package Structure**: Use modular package structure with models/, config/, utils/

### FAL AI Video-to-Video
1. **Dual-Model Architecture**: ThinksSound for audio generation, Topaz for video upscaling
2. **CLI Interface**: Use unified CLI with clear command structure
3. **Cost Management**: ThinksSound (~$0.05-0.10), Topaz (~$0.50-2.50) per video
4. **Batch Processing**: Support batch operations for multiple videos
5. **Frame Interpolation**: Utilize target FPS control for smooth playback

### Text-to-Speech Package
1. **Modular Design**: Keep modules focused (150-300 lines each)
2. **Clean Imports**: Use relative imports within package, absolute from outside
3. **Type Hints**: Always include proper type hints (remember `from typing import List`)
4. **Validation**: Use utils.validators for input validation
5. **Configuration**: Use config/ modules for settings and presets
6. **Testing**: Support dummy API keys for structure testing

### General Project Guidelines
1. **Cost Consciousness**: Always warn about API costs for FAL AI operations
2. **Environment Variables**: Use .env files for API keys, never commit them
3. **Error Handling**: Comprehensive error handling with user-friendly messages
4. **Documentation**: Update README files when adding features
5. **Testing**: Provide both FREE and paid testing options where applicable

### File Organization
- Each implementation has its own folder with clear separation
- Shared utilities in dedicated modules
- Comprehensive README files for each implementation
- Cost-conscious testing frameworks for paid APIs

### Code Style
- Use descriptive variable names
- Include comprehensive docstrings
- Follow Python PEP 8 guidelines
- Prefer composition over inheritance
- Keep functions focused and single-purpose

### API Integration Patterns
- Always validate API keys before making requests
- Implement retry logic with exponential backoff
- Provide detailed error messages for API failures
- Support both synchronous and asynchronous operations where appropriate
- Include rate limiting considerations

### Testing Strategy
- Provide FREE tests that validate structure without API calls
- Include cost warnings for all paid operations
- Support dummy/test API keys for development
- Comprehensive test suites with clear cost implications
- Interactive demos with user confirmation for paid operations

### Security Considerations
- Never commit API keys or sensitive information
- Use environment variables for configuration
- Validate all user inputs
- Implement proper error handling without exposing internals
- Use secure defaults for all configurations

## Specific Implementation Notes

### Google Veo (veo3_video_generation/)
- Requires Google Cloud authentication and complex setup
- Function-based architecture
- GCS bucket integration for file handling
- Comprehensive error handling for cloud operations

### FAL AI Implementations
- Class-based architecture across all FAL modules
- Unified error handling and cost protection
- Simple API key authentication
- Production-ready with cost-conscious design

### AI Content Pipeline (ai_content_pipeline/)
- Unified interface for chaining multiple AI operations
- YAML/JSON-based workflow configuration
- Automatic model selection and cost optimization
- Professional package structure with modular design

### FAL AI Text-to-Video (fal_text_to_video/)
- Direct text-to-video generation (no image step required)
- Multiple model options with different cost/quality trade-offs
- 1080p output with 6-second duration (MiniMax)
- Premium audio support available (Google Veo 3)
- Modular package structure with models/, config/, utils/

### FAL AI Video-to-Video (fal_video_to_video/)
- Dual-model architecture: ThinksSound (audio) + Topaz (upscaling)
- AI-powered audio enhancement for existing videos
- Professional video upscaling up to 4x resolution
- Frame interpolation with target FPS control
- Unified CLI interface and batch processing support

### Text-to-Speech Package
- Professional modular architecture (recently refactored)
- Comprehensive pipeline: AI content generation → speech synthesis
- Support for 3000+ voices and multiple models
- Complete configuration management system
- CLI tools and interactive interfaces

### Video Tools Package
- Enhanced CLI architecture with parameter support (recently implemented)
- Supports both traditional mode and enhanced mode with parameters
- Subtitle generation: SRT/VTT format support with -i/-o/-f parameters
- AI analysis: describe-videos and transcribe-videos with parameter support
- Comprehensive test suite with automated CLI testing

## When Working on This Project

1. **Identify the Implementation**: Understand which component you're working with
2. **Check Documentation**: Each folder has its own README with specific guidelines
3. **Understand Cost Implications**: Be aware of which operations cost money
4. **Follow Architecture Patterns**: Use the established patterns for each implementation
5. **Test Appropriately**: Use FREE tests first, then paid tests with user confirmation
6. **Update Documentation**: Keep README files current with any changes
7. **For Text-to-Speech**: Use the new modular structure, not old monolithic files
8. **For AI Pipeline**: Consider chain operations for complex workflows
9. **For Text-to-Video**: Choose appropriate model based on quality/cost requirements
10. **For Video-to-Video**: Focus on audio enhancement capabilities

## Common Commands

### AI Content Pipeline Development (FLAGSHIP)
```bash
cd ai_content_pipeline

# Sequential execution
python -m ai_content_pipeline run-chain --config input/tts_simple_test.yaml

# Parallel execution (2-3x speedup)
PIPELINE_PARALLEL_ENABLED=true python -m ai_content_pipeline run-chain --config input/tts_parallel_test.yaml

# Test backward compatibility
python tests/test_backward_compatibility.py

# View documentation
cat docs/README.md
cat docs/GETTING_STARTED.md
cat docs/YAML_CONFIGURATION.md
```

### FAL AI Text-to-Video Development
```bash
cd fal_text_to_video

# Test setup (FREE)
python test_setup.py

# Interactive demo with cost warnings
python demo.py

# Generate single video (PAID - requires confirmation)
python test_generation.py --single
```

### FAL AI Video-to-Video Development
```bash
cd fal_video_to_video

# Test setup (FREE)
python tests/test_setup.py

# Add audio to video (PAID - ~$0.05-0.10/video)
python -m fal_video_to_video add-audio -i input/video.mp4 -p "add dramatic music"

# Upscale video (PAID - ~$0.50-2.50/video)
python -m fal_video_to_video upscale -i input/video.mp4 --upscale-factor 2

# Test with sample video
bash test_topaz_upscale.sh
```

### Text-to-Speech Development
```bash
cd text_to_speech
pip install -r requirements.txt

# Test package structure (FREE)
python -c "from text_to_speech import ElevenLabsTTSController; print('✅ Package working!')"

# Run examples
python examples/basic_usage.py
python cli/interactive.py
python cli/quick_start.py
```

### Video Tools Development
```bash
cd video_tools

# Test enhanced CLI functionality
bash tests/test_subtitles_cli.sh

# Enhanced commands with parameters
python3 video_audio_utils.py generate-subtitles -i input/video.mp4 -o output/subtitle.srt -f srt
python3 video_audio_utils.py describe-videos -i input/video.mp4 -o output/description.json
python3 video_audio_utils.py transcribe-videos -i input/video.mp4 -o output/transcript.txt

# Traditional commands (no parameters)
python3 video_audio_utils.py generate-subtitles
python3 video_audio_utils.py describe-videos
```

### Other Implementations
```bash
# Google Veo
cd veo3_video_generation && python test_veo.py

# FAL AI (with cost warnings)
cd fal_image_to_video && python test_api_only.py  # FREE
cd fal_avatar_generation && python test_setup.py  # FREE
```

Remember: 
- **🚀 FLAGSHIP: ai_content_pipeline** provides unified YAML-based pipelines with parallel execution support (2-3x speedup). Use `PIPELINE_PARALLEL_ENABLED=true` for parallel processing.
- The **fal_text_to_video** module offers direct text-to-video generation with dual model support (MiniMax Hailuo-02 Pro vs Google Veo 3) and modular package structure.
- The **fal_video_to_video** module provides dual-model architecture with ThinksSound (audio generation) and Topaz (video upscaling) through unified CLI interface.
- The **text_to_speech** package has a completely refactored, professional modular architecture (15+ focused modules) with OpenRouter AI integration. Always use the new import patterns and module structure.
- The **video_tools** package supports enhanced CLI mode with -i/-o/-f parameters for generate-subtitles, describe-videos, and transcribe-videos commands. Always check for parameter support when working with these commands.
- **Parallel Execution**: Use StepType.PARALLEL_GROUP in YAML configs for concurrent step execution with merge strategies (collect_all, first_success, best_quality).
- **Cost Management**: Always start with FREE tests (test_setup.py, test_api_only.py) before running paid operations. All implementations include cost warnings and confirmation prompts.