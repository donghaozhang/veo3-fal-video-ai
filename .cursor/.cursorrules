# Cursor AI Assistant Rules for Veo3 Video Generation Project

## Project Overview
This is a comprehensive AI content creation project with multiple implementations:

### üöÄ **FLAGSHIP: AI Content Pipeline (ai_content_pipeline/)**
- **Unified YAML-based pipeline** for multi-step content generation
- **Parallel execution support** with 2-3x speedup using thread-based processing
- **All model integration**: FAL AI, ElevenLabs TTS, Google services
- **Feature flag**: `PIPELINE_PARALLEL_ENABLED=true` for parallel execution
- **Command**: `python -m ai_content_pipeline run-chain --config config.yaml`

### Individual Service Implementations:
- Google Veo video generation (veo3_video_generation/)
- FAL AI video generation (fal_video_generation/)
- FAL AI text-to-video generation (fal_text_to_video/)
- FAL AI video-to-video audio enhancement (fal_video_to_video/)
- FAL AI avatar generation (fal_avatar_generation/)
- FAL AI text-to-image (fal_text_to_image/)
- FAL AI image-to-image (fal_image_to_image/)
- **ENHANCED: Modular text-to-speech package with OpenRouter AI (text_to_speech/)**
- **ENHANCED: Video tools with CLI parameter support (video_tools/)**

## **FLAGSHIP: AI Content Pipeline Architecture** (PARALLEL EXECUTION READY)

### Unified Content Creation System with Parallel Processing
The ai_content_pipeline provides a unified interface for chaining multiple AI operations with **parallel execution support**:
**Text ‚Üí Image ‚Üí Video ‚Üí Audio Enhancement ‚Üí Video Upscaling** (Sequential or Parallel)

```
ai_content_pipeline/
‚îú‚îÄ‚îÄ ai_content_pipeline/           # Main package
‚îÇ   ‚îú‚îÄ‚îÄ config/                   # Configuration management
‚îÇ   ‚îú‚îÄ‚îÄ models/                   # Model implementations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ text_to_speech.py     # ElevenLabs TTS integration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ text_to_image.py      # FAL AI image generation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ image_to_image.py     # FAL AI image modification
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ base.py               # Base model interface
‚îÇ   ‚îú‚îÄ‚îÄ pipeline/                 # Pipeline management
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ manager.py            # Main pipeline manager
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chain.py              # Chain configuration classes
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ executor.py           # Chain execution engine
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ parallel_extension.py # **NEW: Parallel execution module**
‚îÇ   ‚îú‚îÄ‚îÄ utils/                    # File management and validation
‚îÇ   ‚îú‚îÄ‚îÄ docs/                     # **NEW: Complete documentation**
‚îÇ   ‚îú‚îÄ‚îÄ examples/                 # **NEW: Example scripts and POCs**
‚îÇ   ‚îî‚îÄ‚îÄ input/                    # YAML configuration files
```

### **NEW: Parallel Execution Features**
- **StepType.PARALLEL_GROUP**: Execute multiple steps concurrently
- **Thread-based processing**: 2-3x speedup for parallel operations
- **Merge strategies**: collect_all, first_success, best_quality
- **Feature flag**: `PIPELINE_PARALLEL_ENABLED=true`
- **Backward compatible**: Zero breaking changes to existing workflows

### Pipeline Usage Patterns
```python
# ‚úÖ Correct - YAML-based pipeline execution
# Sequential execution
python -m ai_content_pipeline run-chain --config input/tts_simple_test.yaml

# Parallel execution (2-3x speedup)
PIPELINE_PARALLEL_ENABLED=true python -m ai_content_pipeline run-chain --config input/tts_parallel_test.yaml

# Debug mode
python -m ai_content_pipeline run-chain --config config.yaml --debug
```

```yaml
# ‚úÖ YAML Configuration Example - Parallel TTS Generation
pipeline_name: "parallel_tts_example"
description: "Generate multiple TTS files in parallel"
output_directory: "ai_content_pipeline/output/"

steps:
  - step_type: "parallel_group"
    parallel_config:
      merge_strategy: "collect_all"
    steps:
      - step_type: "text_to_speech"
        config:
          text: "Hello from voice 1"
          voice: "Adam"
        output_filename: "voice1.mp3"
      - step_type: "text_to_speech"
        config:
          text: "Hello from voice 2"
          voice: "Rachel"
        output_filename: "voice2.mp3"
```

## FAL AI Text-to-Video Architecture (RECENTLY ADDED)

### Unified Text-to-Video Generation
The fal_text_to_video module provides direct text-to-video generation with multiple model options:

```
fal_text_to_video/
‚îú‚îÄ‚îÄ fal_text_to_video_generator.py # Main generator class
‚îú‚îÄ‚îÄ test_setup.py                  # FREE setup validation
‚îú‚îÄ‚îÄ test_generation.py             # PAID generation tests
‚îú‚îÄ‚îÄ demo.py                        # Interactive demonstration
‚îî‚îÄ‚îÄ README.md                      # Complete documentation
```

### Model Support
- **MiniMax Hailuo-02 Pro** (Default): $0.08/video, 1080p, 6s duration
- **Google Veo 3** (Premium): $2.50-$6.00/video, 720p, 5-8s duration, audio support

### Import Patterns
```python
# ‚úÖ Correct - Text-to-video generation
from fal_text_to_video_generator import FALTextToVideoGenerator, TextToVideoModel

generator = FALTextToVideoGenerator(verbose=True)
result = generator.generate_video(
    prompt="A majestic eagle soaring over mountains",
    model=TextToVideoModel.MINIMAX_HAILUO  # Cost-effective option
)
```

## FAL AI Video-to-Video Architecture (RECENTLY ADDED)

### AI Audio Enhancement for Videos
The fal_video_to_video module adds AI-generated audio to existing videos using ThinkSound:

```
fal_video_to_video/
‚îú‚îÄ‚îÄ fal_video_to_video/            # Main package
‚îú‚îÄ‚îÄ test_topaz_upscale.sh          # Video upscaling test
‚îú‚îÄ‚îÄ setup.py                       # Professional package setup
‚îú‚îÄ‚îÄ README.md                      # Complete documentation
‚îî‚îÄ‚îÄ examples/                      # Usage examples
```

### Audio Enhancement Features
- **ThinkSound API**: AI-powered video audio generation
- **Text Prompts**: Guide audio generation with natural language
- **Multiple Formats**: MP4, MOV, AVI, WebM support
- **Cost-Effective**: ~$0.001 per second of video

### Import Patterns
```python
# ‚úÖ Correct - Video audio enhancement
from fal_video_to_video import FALVideoToVideoGenerator

generator = FALVideoToVideoGenerator()
result = generator.add_audio_to_local_video(
    video_path="input/my_video.mp4",
    prompt="add ambient nature sounds"
)
```

## Text-to-Speech Package Architecture (RECENTLY REFACTORED)

### Package Structure
The text_to_speech package has been refactored from monolithic files to a professional modular structure:

```
text_to_speech/
‚îú‚îÄ‚îÄ models/          # Data models and enums
‚îÇ   ‚îú‚îÄ‚îÄ common.py    # Shared models (VoiceSettings, AudioFormat, etc.)
‚îÇ   ‚îî‚îÄ‚îÄ pipeline.py  # Pipeline-specific models
‚îú‚îÄ‚îÄ tts/             # Core TTS functionality
‚îÇ   ‚îú‚îÄ‚îÄ controller.py      # Main TTS controller
‚îÇ   ‚îú‚îÄ‚îÄ voice_manager.py   # Voice selection and management
‚îÇ   ‚îî‚îÄ‚îÄ audio_processor.py # Audio format handling
‚îú‚îÄ‚îÄ pipeline/        # OpenRouter AI integration
‚îÇ   ‚îî‚îÄ‚îÄ core.py      # Complete pipeline orchestration
‚îú‚îÄ‚îÄ utils/           # Utility functions
‚îÇ   ‚îú‚îÄ‚îÄ file_manager.py    # File operations
‚îÇ   ‚îú‚îÄ‚îÄ api_helpers.py     # API utilities
‚îÇ   ‚îî‚îÄ‚îÄ validators.py      # Input validation
‚îú‚îÄ‚îÄ config/          # Configuration management
‚îÇ   ‚îú‚îÄ‚îÄ voices.py    # Voice presets and configurations
‚îÇ   ‚îú‚îÄ‚îÄ models.py    # Model settings and recommendations
‚îÇ   ‚îî‚îÄ‚îÄ defaults.py  # Default values and settings
‚îú‚îÄ‚îÄ examples/        # Usage examples
‚îÇ   ‚îî‚îÄ‚îÄ basic_usage.py     # Basic TTS examples
‚îî‚îÄ‚îÄ cli/             # Command line tools
    ‚îú‚îÄ‚îÄ interactive.py     # Interactive pipeline
    ‚îî‚îÄ‚îÄ quick_start.py     # Quick demo runner
```

### Import Patterns
**Always use the new modular imports:**
```python
# ‚úÖ Correct - Main package interface
from text_to_speech import ElevenLabsTTSController, ElevenLabsModel, VoiceSettings

# ‚úÖ Correct - Direct module imports
from text_to_speech.tts.controller import ElevenLabsTTSController
from text_to_speech.models.common import ElevenLabsModel, VoiceSettings
from text_to_speech.pipeline.core import OpenRouterTTSPipeline

# ‚ùå Avoid - Old monolithic imports (removed)
from elevenlabs_tts_controller import ElevenLabsTTSController  # FILE REMOVED
from openrouter_tts_pipeline import OpenRouterTTSPipeline      # FILE REMOVED
```

### Migration Notes
- Old monolithic files have been removed: elevenlabs_tts_controller.py, openrouter_tts_pipeline.py, elevenlabs_dialogue_controller.py
- All functionality preserved in new modular structure
- Migration guide available: text_to_speech/MIGRATION_GUIDE.md
- Backward compatibility maintained through main package interface

## Video Tools Enhanced CLI Architecture (RECENTLY IMPLEMENTED)

### Enhanced Commands with Parameter Support
The video_tools package now supports enhanced CLI parameter mode for specific commands:

```bash
# Enhanced generate-subtitles with -i, -o, -f parameters
python3 video_audio_utils.py generate-subtitles -i video.mp4 -o subtitle.srt
python3 video_audio_utils.py generate-subtitles -i input/ -o output/ -f vtt

# Enhanced describe-videos with parameters
python3 video_audio_utils.py describe-videos -i video.mp4 -o output.json -f describe-video

# Enhanced transcribe-videos with parameters  
python3 video_audio_utils.py transcribe-videos -i video.mp4 -o output.json -f json
```

### Parameter Support Pattern
Commands support enhanced mode when `-i`, `-o`, or `-f` parameters are provided:
- `-i`: Input file or directory path
- `-o`: Output file or directory path  
- `-f`: Format specification (varies by command)

### Implementation Pattern
Enhanced commands follow this architecture:
1. `cmd_[command]_enhanced()` wrapper function in video_audio_utils.py
2. `cmd_[command]_with_params()` implementation in respective modules
3. Automatic detection and routing based on parameter presence
4. Backward compatibility with traditional mode (no parameters)

## Development Guidelines

### AI Content Pipeline
1. **Chain Design**: Use YAML/JSON for complex workflows
2. **Model Selection**: Prefer "auto" selection with criteria and budget constraints
3. **Cost Estimation**: Always provide transparent cost estimates
4. **File Management**: Use temporary directories and cleanup
5. **Validation**: Validate chain compatibility before execution

### FAL AI Text-to-Video
1. **Model Selection**: Use MiniMax Hailuo-02 Pro for cost-effective generation, Google Veo 3 for premium quality
2. **Cost Consciousness**: Always warn about costs ($0.08-$6.00 per video)
3. **Setup Testing**: Use `test_setup.py` for FREE validation before paid operations
4. **Prompt Optimization**: Enable prompt optimization for better results

### FAL AI Video-to-Video
1. **Audio Enhancement**: Focus on realistic audio generation with text prompts
2. **File Format Support**: Handle multiple video formats (MP4, MOV, AVI, WebM)
3. **Cost Efficiency**: Very cost-effective at ~$0.001 per second
4. **Batch Processing**: Support batch operations for multiple videos

### Text-to-Speech Package
1. **Modular Design**: Keep modules focused (150-300 lines each)
2. **Clean Imports**: Use relative imports within package, absolute from outside
3. **Type Hints**: Always include proper type hints (remember `from typing import List`)
4. **Validation**: Use utils.validators for input validation
5. **Configuration**: Use config/ modules for settings and presets
6. **Testing**: Support dummy API keys for structure testing

### General Project Guidelines
1. **Cost Consciousness**: Always warn about API costs for FAL AI operations
2. **Environment Variables**: Use .env files for API keys, never commit them
3. **Error Handling**: Comprehensive error handling with user-friendly messages
4. **Documentation**: Update README files when adding features
5. **Testing**: Provide both FREE and paid testing options where applicable

### File Organization
- Each implementation has its own folder with clear separation
- Shared utilities in dedicated modules
- Comprehensive README files for each implementation
- Cost-conscious testing frameworks for paid APIs

### Code Style
- Use descriptive variable names
- Include comprehensive docstrings
- Follow Python PEP 8 guidelines
- Prefer composition over inheritance
- Keep functions focused and single-purpose

### API Integration Patterns
- Always validate API keys before making requests
- Implement retry logic with exponential backoff
- Provide detailed error messages for API failures
- Support both synchronous and asynchronous operations where appropriate
- Include rate limiting considerations

### Testing Strategy
- Provide FREE tests that validate structure without API calls
- Include cost warnings for all paid operations
- Support dummy/test API keys for development
- Comprehensive test suites with clear cost implications
- Interactive demos with user confirmation for paid operations

### Security Considerations
- Never commit API keys or sensitive information
- Use environment variables for configuration
- Validate all user inputs
- Implement proper error handling without exposing internals
- Use secure defaults for all configurations

## Specific Implementation Notes

### Google Veo (veo3_video_generation/)
- Requires Google Cloud authentication and complex setup
- Function-based architecture
- GCS bucket integration for file handling
- Comprehensive error handling for cloud operations

### FAL AI Implementations
- Class-based architecture across all FAL modules
- Unified error handling and cost protection
- Simple API key authentication
- Production-ready with cost-conscious design

### AI Content Pipeline (ai_content_pipeline/)
- Unified interface for chaining multiple AI operations
- YAML/JSON-based workflow configuration
- Automatic model selection and cost optimization
- Professional package structure with modular design

### FAL AI Text-to-Video (fal_text_to_video/)
- Direct text-to-video generation (no image step required)
- Multiple model options with different cost/quality trade-offs
- 1080p output with 6-second duration (MiniMax)
- Premium audio support available (Google Veo 3)

### FAL AI Video-to-Video (fal_video_to_video/)
- AI-powered audio enhancement for existing videos
- ThinkSound API integration
- Very cost-effective audio generation
- Multiple video format support

### Text-to-Speech Package
- Professional modular architecture (recently refactored)
- Comprehensive pipeline: AI content generation ‚Üí speech synthesis
- Support for 3000+ voices and multiple models
- Complete configuration management system
- CLI tools and interactive interfaces

### Video Tools Package
- Enhanced CLI architecture with parameter support (recently implemented)
- Supports both traditional mode and enhanced mode with parameters
- Subtitle generation: SRT/VTT format support with -i/-o/-f parameters
- AI analysis: describe-videos and transcribe-videos with parameter support
- Comprehensive test suite with automated CLI testing

## When Working on This Project

1. **Identify the Implementation**: Understand which component you're working with
2. **Check Documentation**: Each folder has its own README with specific guidelines
3. **Understand Cost Implications**: Be aware of which operations cost money
4. **Follow Architecture Patterns**: Use the established patterns for each implementation
5. **Test Appropriately**: Use FREE tests first, then paid tests with user confirmation
6. **Update Documentation**: Keep README files current with any changes
7. **For Text-to-Speech**: Use the new modular structure, not old monolithic files
8. **For AI Pipeline**: Consider chain operations for complex workflows
9. **For Text-to-Video**: Choose appropriate model based on quality/cost requirements
10. **For Video-to-Video**: Focus on audio enhancement capabilities

## Common Commands

### AI Content Pipeline Development (FLAGSHIP)
```bash
cd ai_content_pipeline

# Sequential execution
python -m ai_content_pipeline run-chain --config input/tts_simple_test.yaml

# Parallel execution (2-3x speedup)
PIPELINE_PARALLEL_ENABLED=true python -m ai_content_pipeline run-chain --config input/tts_parallel_test.yaml

# Test backward compatibility
python tests/test_backward_compatibility.py

# View documentation
cat docs/README.md
cat docs/GETTING_STARTED.md
cat docs/YAML_CONFIGURATION.md
```

### FAL AI Text-to-Video Development
```bash
cd fal_text_to_video

# Test setup (FREE)
python test_setup.py

# Interactive demo with cost warnings
python demo.py

# Generate single video (PAID - requires confirmation)
python test_generation.py --single
```

### FAL AI Video-to-Video Development
```bash
cd fal_video_to_video

# Test setup (FREE)
python tests/test_setup.py

# Add audio to video (PAID - low cost ~$0.001/second)
python -m fal_video_to_video add-audio -i input/video.mp4 -p "add dramatic music"
```

### Text-to-Speech Development
```bash
cd text_to_speech
pip install -r requirements.txt

# Test package structure (FREE)
python -c "from text_to_speech import ElevenLabsTTSController; print('‚úÖ Package working!')"

# Run examples
python examples/basic_usage.py
python cli/interactive.py
python cli/quick_start.py
```

### Video Tools Development
```bash
cd video_tools

# Test enhanced CLI functionality
bash tests/test_subtitles_cli.sh

# Enhanced commands with parameters
python3 video_audio_utils.py generate-subtitles -i input/video.mp4 -o output/subtitle.srt -f srt
python3 video_audio_utils.py describe-videos -i input/video.mp4 -o output/description.json
python3 video_audio_utils.py transcribe-videos -i input/video.mp4 -o output/transcript.txt

# Traditional commands (no parameters)
python3 video_audio_utils.py generate-subtitles
python3 video_audio_utils.py describe-videos
```

### Other Implementations
```bash
# Google Veo
cd veo3_video_generation && python test_veo.py

# FAL AI (with cost warnings)
cd fal_image_to_video && python test_api_only.py  # FREE
cd fal_avatar_generation && python test_setup.py  # FREE
```

Remember: 
- **FLAGSHIP: ai_content_pipeline** provides unified YAML-based pipelines with parallel execution support (2-3x speedup). Use `PIPELINE_PARALLEL_ENABLED=true` for parallel processing.
- The fal_text_to_video module offers direct text-to-video generation with multiple model options (cost-effective vs premium).
- The fal_video_to_video module specializes in AI audio enhancement for existing videos at very low cost.
- The text_to_speech package has a completely refactored, professional modular architecture with OpenRouter AI integration. Always use the new import patterns and module structure.
- The video_tools package now supports enhanced CLI mode with -i/-o/-f parameters for generate-subtitles, describe-videos, and transcribe-videos commands. Always check for parameter support when working with these commands.
- **Parallel Execution**: Use StepType.PARALLEL_GROUP in YAML configs for concurrent step execution with merge strategies (collect_all, first_success, best_quality).